[["index.html", "Clinical Trials 4H Welcome to Clinical Trials 4H! Practical details What to expect from this module", " Clinical Trials 4H Rachel Oughton 2025-01-27 Welcome to Clinical Trials 4H! This page contains the notes for Clinical Trials IV 2024-25. As we progress through the course, more will appear. You can also download the PDF version (see the icon at the top left). If you notice any typos, mistakes or places that are unclear, please do let me know! In case you’re reading the PDF, the notes are best viewed in HTML (the link is https://racheloughton.github.io/ct4/). The PDF will be up-to-date, but the formatting is designed for HTML. Practical details Lectures Our lectures are 9am on Wednesdays in W007 (this is the Appleby Building, between Pysics and the main library), and 3pm on Fridays in PCL 048 (this is in the ground floor of the Palatine Centre). Computer classes We have four computer practicals for this module. They are 1-2pm on the Mondays of weeks 13, 15, 17 and 19. These classes are in MCS 3098. Office Hour The office hour will be every Wednesday, 10-11am, in the Calman Learning Centre cafe. Assessment This module is assessed through two equally weighted pieces of coursework. The first will be assigned on Wednesday 7th February (due 3rd March), the second on Wednesday 19th March (due 5th May). There will also be two formative assignments during the course. More details on these to follow. Books and resources The main reference for the first half of the course is Matthews (2006). There are a couple of copies in the Bill Bryson Library. Some other books we will make use of are Hulley et al. (2013), Hayes and Moulton (2017). You shouldn’t need to use any of these books, but of course you’re welcome to if you want to read further. I will share links along the way for relevant resources like podcast episodes and articles, which I hope will help you to get a feel for the topic more generally. What to expect from this module Clinical Trials IV is somewhat different from the majority of statistics modules, because Its main focus is on application It is assessed purely through coursework. This means that your experience of it might be different from what you’re used to We will cover quite a lot of different statistical methods (drawing on most of the 1H and 2H courses, and some 3H!) but not in great depth There is no pressure to memorize anything - indeed, if you really were a trial statistician, you would definitely have access to the internet, various textbooks and even these notes (should they prove useful!). There is an emphasis on understanding which method we use and why, and what it means. Hopefully this has been the case in some of your other modules too! What I expect from you Because we will be covering quite a lot of different areas within statistics, there may be some things that you haven’t seen before (or can’t remember very well). I will try my best to explain them as clearly as I can, but there isn’t time to go into the nuts and bolts of everything we come across. Therefore, if you do feel a bit rusty on some area, you may need to read up on that a bit, so that you’re happy with it. I am very happy to suggest resources from time to time, and you’re welcome to come to the office hour to talk about such things. This course is in its infancy, and so I would also really appreciate your feedback. I may not be able to address everything (or I may only be able to implement things for following years), but if I can act on it quickly then I will! References Hayes, Richard J, and Lawrence H Moulton. 2017. Cluster Randomised Trials. CRC press. Hulley, Stephen B, Steven R. Cummings, Warren S. Browner, Deborah G. Grady, and Thomas B. Newman. 2013. Designing Clinical Research, Fourth Edition. Lippincott Williams &amp; Wilkins. Matthews, John NS. 2006. Introduction to Randomized Controlled Clinical Trials. CRC Press. "],["rct-intro.html", "1 Introduction to Clinical Trials 1.1 Causal inference and clinical trials 1.2 The structure of a clinical trial 1.3 The primary outcome 1.4 Ethical issues 1.5 Phases of clinical trials", " 1 Introduction to Clinical Trials A clinical trial is an experiment, usually performed on human subjects, to test the effect of some sort of treatment or intervention. We may also use the term Randomised controlled trial (RCT). These are not fully the same thing; a clinical trial may not have been randomised, for example if it follows a pre-determined cohort through some sort of process. Likewise, an RCT may not be clinical, but instead may be about an intervention in some other setting like agriculture or education. For this module, we are really focussing on RCTs, and almost all of our examples will be clinical. For the purposes of this module, a clinical trial will have two groups: The treatment group or intervention group: this group of people will be subject to the new treatment. The control group: this group of people will be subject to the status quo - the ‘standard’ or most widely used treatment path for their cohort (sometimes this is no treatment). These groups are usually, though not always, of the same size. Which group each patient is assigned to is usually decided by randomization, which is something we will go on to explore in later lectures. In reality, trials can have more than two groups, and many statistical methods extend quite naturally to this. The goal of the trial is to estimate the treatment effect: is the treatment better than the control, and if so, how much? This short description raises lots of statistical issues, which will take up the next few weeks! Before we get into the theory, we’ll think about some of the background to clinical trials, and introduce some key ideas. Put (very!) simply, the goal of a clinical trial is to determine what works to make people better. Although clinical trials as we know them now have only been around since the Second World War, similar sorts of experiments can be seen from much longer ago. If you’re interested in learning about the evolution of clinical trials from Biblical times to now, the James Lind Library has some fascinating resources and articles. Example 1.1 Scurvy (James Lind, 1757) Scurvy was a serious disease, particularly affecting seamen on long voyages. Symptoms were unpleasant (mouth sores, skin lesions etc.) and it could often be fatal. Lind was the ship’s surgeon on board the HMS Salisbury, and had several patients with scurvy. Many remedies were proposed and in popular use at the time (with only anecdotal evidence, if any, to support them). In 1757 Lind decided to test six such treatments, on two patients each: cider dilute sulfuric acid vinegar sea water citrus (oranges and lemons) purgative mixture (a paste of garlic, mustard seed, horseradish, balsam of Peru, and gum myrrh) Lind chose twelve seamen with similar severity of symptoms, and subjected them to their assigned treatment for 6 days. They were kept in the same quarters, and fed the same diet apart from their treatment. Unsurprisingly (to us!) “The most sudden and visible good effects were perceived from the use of oranges and lemons,” A key thing to notice about the Scurvy example is that Lind went to great lengths to ensure that the treatment was the only thing affecting these 12 sailors: they all started with a similar severity of symptoms, they were kept in the same place and their diet was identical apart from their treatment. This links to one of the foundational principles of clinical trials: causal inference. 1.1 Causal inference and clinical trials You’re probably familiar with the mantra that “correlation does not imply causation”: just because two things are correlated, it doesn’t mean we can conclude that one causes the other. If you’re not convinced, here are some humorous (and slightly macabre) examples. Causal inference is concerned with the design and analysis of data for uncovering causal relationships. This is important for us, because we really want to be able to conclude that a treatment works (or doesn’t) - that it causes recovery, or a reduction in symptoms, or helps the patient in some way. If we were experimental scientists in some laboratory, we could conduct some controlled experiment in which everything was kept under very specific conditions, and could fairly easily make conclusions about the treatment we were testing, and how it behaved in a range of conditions. However, testing treatments on real people is different: we don’t have several identical versions of the same person to test the treatment on, and even if we did, as Gwyneth Paltrow shows us it doesn’t take very much to completely alter the conditions of someone’s existence! Neither can we just base our conclusion of whether a treatment works on lab-based tests or theory (although undoubtedly these will both play a part in developing the treatment in the first place). The treatment needs to be tested on actual people. Because, as we noted, people are all different, and living different lives (and unlike James Lind we can’t force them all to live in the same part of a ship and eat the same food!) we will need to test the treatment on lots of people in order to gather empirical evidence. This is why statistics is so important in the design and analysis of clinical trials. The results of the trial must concluded beyond reasonable doubt, and must be able to be generalized to as-yet-untreated patients. We want to avoid any spurious correlations that are down to chance, or to associations we haven’t taken into account. For example, what if the two seamen given citrus were also much younger and generally healthier than the other ten? Maybe they would have recovered quickly anyway? Or what if another treatment was actually much better than citrus, but just happened to have been given to two sailors who had some other pre-existing illness, causing them to suffer much worse with scurvy? Clinical trials are therefore crucial for modern medicine, and statistics is crucial to clinical trials. But why exactly are clinical trials given this position of importance? Do we really have to do things this way? 1.2 The structure of a clinical trial In a clinical trial, people are grouped and subdivided in various ways. The population of eligible patients One of the first steps in conducting a trial is to specify exactly what sort of person you want to test the treatment on, and where these people will be found. They may be of a certain sex and/or age range, they may have (or definitely not have) certain conditions. They may suffer from some particular symptom, or be at a particular stage of an illness. A clear set of criteria is key to consistency. Patients are usually recruited as they present (eg. to hospital or a GP centre) and may be being recruited over several years, or by several different clinicians, so it is important that everyone is sticking to the same plan. Example 1.2 In a study by Hjalmas and Hellstrom (1998) of the use of desmopressin in children with nocturnal enuresis (bed-wetting), children had to be aged 6 - 12 with a history of PMNE (primary monosymptomatic nocturnal enuresis) and no organic pathology (no disease that alters the structure or function of organs). The children had to be free of other urinary problems (such as frequency, urgency or daytime incontinence) and not to have received any treatment for nocturnal enuresis during the 2 months before entering the trial. Children with clinically significant endocrine, metabolic, hepatic, psychiatric, neurological, musculoskeletal, cardiovascular, haematological, renal or genitourinary disease were excluded from the trial. Knowing exactly what type of patients were recruited into the trial is also key when generalizing the results to the population. If the trial recruited males aged 55-70, we cannot confidently conclude that the results will apply to a female aged 26. Entry to the trial The group of patients recruited will be some subset of the possible population. Patients are allowed to refuse consent to take part, or individual patients may be judged unsuitable despite meeting the criteria. Knowing how many patients to recruit is a statistical question, which we will deal with soon. Allocation to groups These patients are then allocated to receive either the treatment, or to be part of the control group (or more, if there are more than two groups). These groups are often referred to as the trial arms - the treatment arm and the control arm. Deciding which patients should be allocated to which group is another statistical question. Once the patients have been allocated, they will receive the treatment (or not) and important measurements will be taken during the trial period. Comparing results Now that the trial has been run, we have two sets of measurements: one for the treatment group and one for the control group. But guess what?! Comparing these and coming to a conclusion about the effect of the treatment is a statistical question. Why bother with a control group? Surely if we want to see whether a treatment works, we should just give it to a patient and see if they get better? Why do we need to also have a group of people not receiving the treatment? In rare and extreme cases, this is a decent strategy: if a disease has always been fatal, but we start giving patients the treatment and some live, that is pretty solid evidence that the treatment works. This was the case with tuberculous meningitis, until the introduction of Streptomycin in 1944. This was also the case when Edward Jenner tested cowpox as a vaccination for the fatal disease smallpox. After observing that milkmaids, once they had suffered from the mild condition cowpox (which they did often), seemed to be immune to smallpox, Jenner tested his theory by injecting an 8 year old boy called James Phipps with fluid from a milkmaid’s cowpox lesions (yum). Once the boy’s cowpox infection had run its course, he injected him again, this time with matter from a fresh smallpox lesion. Thankfully, James Phipps did not contract smallpox. After several more successful such tests, and a gradual shift in attitudes to the idea of vaccination (a word coined by Jenner, from the latin ‘vaccinia’, meaning cowpox) Jenner’s results were published and vaccination became commonplace. Clearly, injecting people with smallpox who had not been given the cowpox innoculation would be very cruel (they would almost certainly die) and would prove nothing; there was already plenty of evidence for the fatality of smallpox. However, most diseases have a fairly uncertain and variable trajectory. If we give a group of patients the treatment, we can’t know what would have happened to them if they hadn’t received the treatment, or had received a different treatment. Comparing them to patients the past is dodgy because lots of other things may have changed since even the recent past. This is why we have a concurrent control group (usually known as just the control group). These patients do not receive the new treatment, but instead carry on as usual. The aim is to make the control and treatment groups as similar as possible in all other respects (especially those we deem important) so that at the end we can attribute the difference between the two groups to the treatment. 1.3 The primary outcome In a clinical trial, there are usually many measurements performed on patients, and possibly at various different points throughout the trial. However, for the sake of the analysis, we usually determine one to be the primary outcome variable. The research questions should be phrased in terms of this variable, and the goal of our design should be to be able to answer questions about this variable. Example 1.3 In a trial by Villar et al. (2020) investigating the use of Dexamethasone treatment for acute respiratory distress syndrome , the primary outcome was the ‘number of ventilator free days up to 28 days’, while other outcomes included ‘all-cause mortality after 60 days’ and ‘incidence of infections in ICU’. 1.4 Ethical issues Clinical trials differ from most scientific experiments in that they are experimenting on people. This means that the team designing, conducting and analysing the trial have various ethical responsibilities. This is a huge area; we will touch on it from time to time but will not go into anywhere near enough detail! Some key things to note though are…. A patient must never be given a treatment that is known to be inferior. Patients must be fully informed about the trial, the treatments used, possible adverse effects and side-effects and so on. Patients should only be recruited into the trial if, after being given all this information (and having had it communicated clearly and at an appropriate level) they give their consent. After entering a trial, a patient has the right to withdraw at any point, and should then receive whatever treatment is most appropriate for them. They should not face any negative repurcussions for withdrawing. The patients’ interests are safeguarded by the Declaration of Helsinki. This statement is implemented differently by different countries. In the UK, health authorities each have their own ethics committee, by which proposals for experiments involving human subjects must be approved. You might think that these ethical issues largely concern the clinicians, and that we statisticians don’t need to worry too much about the ethics of clinical trials. After all, we are likely never to meet any patients or to get our hands dirty in any way! But as we will see, at each stage the choices made by the statistician can in fact have serious ethical implications. 1.5 Phases of clinical trials If you read about clinical trials (or hear about them in the news), you’ll hear talk of a ‘phase 3 trial’ or similar. Broadly speaking, clinical trials follow a progression from phase one (or sometimes zero) to phase four. These phases apply to most countries, and any for any drug to be licensed multinationally it must get through phase III. Phase zero The first step is to test a low dose of the treatment on a small number of people, to check that it isn’t harmful. The dose is too low to have any medicinal effect, but is designed to verify that the drug behaves as expected from laboratory studies, and doesn’t have any harmful effects. There may only be 10-20 participants, and there is no randomisation (or control group). Phase one Phase one trials are also quite small (around 20-50 participants) and are designed to find the best dose of the treatment and what any side effects are. Phase one trials tend to be recruited very slowly: a small group will be recruited onto a low dose and monitored closely. If all goes well, another small group will be recruited on a slightly higher dose, and so on. This is known as a dose escalation study. Participants at this phase are monitored very closely, for example through regular blood tests and recording daily symptoms. Phase two If the drug makes it through the phase one trial, it can progress to phase two (often written as ‘phase II’). These involve more people than phase one, possibly up to 100. The cohort may now be restricted to people with a particular version of a condition (eg. a particular type of cancer), but it may still be broader than the sorts of trials we will be looking at. Now the aim is to find out if the new treatment works well enough to progress to a large phase three (phase III) trial: Exactly what conditions (or versions of a condition) does this treatment work for? What are the side effects and can they be managed? What is the best dose to administer? Phase II trials sometimes compare the treatment to a placebo, and sometimes use randomisation to group participants. This is the stage at which most drugs fail, for a multitude of reasons (cost, safety, efficacy,…). Phase three Phase III trials are much bigger, often involving hundreds or thousands of participants, and aim to compare the new treatment to the best currently available treatment (which may be another treatment, or may be nothing). Side effects are still monitored, as some of the rarer ones may not show themselves at the smaller phases, because there are fewer participants. In phase III trials, the aim is to find out if the new treatment is better, and if so by how much. Phase III trials almost always use randomisation to allocate participants to groups, and go to great lengths to make the trial as reliable as possible, for example using a placebo for the control group (who aren’t getting the real treatment) that looks identical to the real drug. These are the sorts of trials we will mainly be concerned with in this course. To be licensed, a treatment has to get through phase III and be found to be effective (and of course safe). Phase four Phase IV trials happen after the treatment has been found to work, has been licensed and is in use. The aims of phase IV trials are to find out more about the rarer side effects to investigate the long term risks and benefits to find out how well the treatment works when given to a broader group of people than in phase III. References Hjalmas, Hanson, and Kruse Hellstrom. 1998. “Long‐term Treatment with Desmopressin in Children with Primary Monosymptomatic Nocturnal Enuresis: An Open Multicentre Study.” British Journal of Urology. Villar, Jesús, Carlos Ferrando, Domingo Martı́nez, Alfonso Ambrós, Tomás Muñoz, Juan A Soler, Gerardo Aguilar, et al. 2020. “Dexamethasone Treatment for the Acute Respiratory Distress Syndrome: A Multicentre, Randomised Controlled Trial.” The Lancet Respiratory Medicine 8 (3): 267–76. "],["rct-plan.html", "2 Sample size for a normally distributed primary outcome variable 2.1 The treatment effect 2.2 Reminder: hypothesis tests (with a focus on RCTs) 2.3 Constructing a measure of effect size 2.4 Power: If \\(H_0\\) is false 2.5 A sample size formula", " 2 Sample size for a normally distributed primary outcome variable For most of this module, we’ll focus on randomised controlled trials (RCTs). These have mainly been used for clinical applications (for example, to test a particular drug), but have also recently become popular ways to test interventions in areas such as education and policing. Having laid the groundwork in Chapter 1, we now go on to some more technical details. In this Chapter, we focus on the ‘vanilla’ scenario, where we have a trial with two arms, and our unit of randomization is individuals. At first we will focus only on continuous outcomes, but in later weeks we will go on to think about binary and time-to-event data. The topics we cover fall into the categories of ‘before the trial’ (design and planning) or ‘after the trial’ (analysis), although as we’ll see there is some interaction between these stages. The first big question asked of a trial statistician is usually how many participants does the trial need in order to be viable: the sample size. We will clarify what is meant by ‘viable’ later in this section. Broadly speaking, there are two (opposing) ethical issues around sample size: If we don’t recruit enough patients, then we may not gather enough evidence to draw any conclusion about the research question (eg. whether there is a treatment effect). As well as being scientifically disappointing, this is unethical. To conduct the trial, some of the patients will have been subject to an inferior treatment (assuming one treatment was actually better), and if there is no conclusion then this was effectively for no purpose. If we recruit too many patients (ie. we would be sufficiently likely to reach a conclusion with many fewer) then we have subjected more patients than necessary to an inferior treatment, and possibly also taken up more time and resources than was necessary. It is therefore important to think about this issue carefully. We’ve framed the question in quite a woolly way so far, but now we’ll start to think more carefully. 2.1 The treatment effect In Section 1.3 we discussed the need to settle on a primary outcome variable. One reason this is important is that we base our sample size calculations on the primary outcome variable. Definition 2.1 Suppose our primary outcome variable is \\(X\\), which has mean \\(\\mu\\) for the control group and mean \\(\\mu + \\tau\\) for the treatment group. The variable \\(\\tau\\) is the treatment effect. The goal of our RCT is to learn about \\(\\tau\\). The larger \\(\\tau\\) is (in magnitude), the more pronounced the effect of the intervention. This problem is usually framed as a hypothesis test, where the null hypothesis is that \\(\\tau=0\\). 2.2 Reminder: hypothesis tests (with a focus on RCTs) When performing a hypothesis test, what we are aiming to find is the P-value. Definition 2.2 The P-value is the probability of obtaining a result as extreme as or more extreme (ie. further away from the null hypothesis value) than the one obtained given that the null hypothesis is true. Put simply, the P-value is a measure of the probability of obtaining whatever result (eg. treatment effect) we have have found simply by random chance, when in fact there is no treatment effect (ie. \\(\\tau=0\\)). Generally, a P-value of \\(\\alpha = 0.05\\) is accepted as sufficient evidence to reject the null hypothesis, although in clinical settings it can often be smaller (eg. \\(\\alpha = 0.01\\)). It is conventional to present the P-value by simply saying whether it is smaller than some threshold (often 0.05), rather than giving the exact value. Definition 2.3 The threshold for the P-value below which the results are considered ‘significant’ is known as the significance level of the test, and is generally written \\(\\alpha\\) (as above). This use of a significance level is (in part) a legacy from early days when computers were rare and values were looked up in \\(t\\)-tables (or similar). Now that it is very simple to find the exact P-value, it is becoming more and more common to report the actual number. Indeed, there is a big difference between \\(p=0.049\\) and \\(p=0.000049\\). 2.2.1 One-tailed or two-tailed? It is highly likely that the scientists running the trial will have a strong idea of the likely ‘direction’ of the treatment effect. Assuming that a larger value of the primary outcome variable \\(X\\) is good, they will expect a positive value of the treatment effect \\(\\tau\\) (or be prepared to accept a possible value of zero for no effect). It would therefore be tempting to perform a one-sided test, with \\[\\begin{align*} H_0\\,&amp;:\\, \\tau=0\\\\ H_1\\,&amp;:\\, \\tau&gt;0. \\end{align*}\\] For example, suppose our test statistic \\(t\\) has a \\(t\\) distribution with 31 degrees of freedom and we obtain a value of 2, as shown in Figure 2.1. In this case our P-value is \\(1 - F_t\\left(2, df=31\\right)= 0.0272\\) (where \\(F_t\\left(\\cdot\\right)\\) is the cumulative distribution function of the \\(t\\) distribution) , and the result would be considered significant at the 0.05 level. Figure 2.1: The distribution \\(t_{31}\\), with the area corresponding to \\(t &gt; 2\\) shaded. For a large positive value of \\(t\\), we obtain a small P-value, and reject \\(H_0\\), concluding that the intervention is effective (in a good way). However, what if we obtain a large negative value of \\(t\\)? In this one-sided set-up, there is no value of \\(t&lt;0\\) that would give a significant result; negative values of \\(t\\) are simply considered consistent with \\(H_0\\), and there is no mechanism to conclude that an intervention has a significantly negative effect. For this reason, we always conduct two sided hypothesis tests, with \\[\\begin{align*} H_0\\,&amp;:\\, \\tau=0\\\\ H_1\\,&amp;:\\, \\tau\\neq 0. \\end{align*}\\] In this scenario, Figure 2.1 is replaced by the plot shown in Figure 2.2, where values of \\(t\\) with \\(t&lt;-2\\) are considered ‘equivalent’ to those with \\(t&gt;2\\), in the sense of how unlikely they are under \\(H_0\\). Figure 2.2: The distribution \\(t_{31}\\), with the area corresponding to \\(|t| &gt; 2\\) shaded. The P-value for the two-sided test as shown in Figure 2.2 is \\[ F\\left(-2, df=31\\right) + \\left[1 - F\\left(2, df=31\\right)\\right] = 2\\times{0.0272} = 0.0543\\] and the result is no longer significant at the 0.05 level. Throughout this course, we will always assume two-tailed tests. Figure 2.3: A rather ubiquitous two-tailed mermaid 2.2.2 Insignificant results If our P-value is relatively large, say 0.3 or 0.5 (or really, greater than \\(\\alpha\\)), then our result is not at all unlikely (or sufficiently unlikely) under the null hypothesis, and provides insufficient evidence to reject \\(H_0.\\) However, it is not inconsistent with the existence of a treatment effect, so we don’t say there is evidence to accept \\(H_0\\). One can imagine that if the true treatment effect \\(\\tau\\) were tiny, many trials would fail to find evidence to reject \\(H_0\\). However, if our sample size were sufficiently large, we should be able to detect it. Conversely, if \\(\\tau\\) is very large, even a relatively small sample size is likely to provide enough evidence to reject \\(H_0\\). A non-significant P-value means that our results are consistent with the null hypothesis \\(\\tau=0\\), but they are also consistent with some small treatment effect, and therefore we can’t conclude very much. The key issue is, what size of treatment effect do we care about? We must ensure that our sample size is large enough to be sufficiently likely to detect a clinically meaningful treatment effect. We are being vague for now, but this is a key issue in determining an appropriate sample size. 2.3 Constructing a measure of effect size Let’s say we are recruiting participants into two groups: group \\(T\\) will be given the new treatment (they will sometimes be referred to as the treatment group or treatment arm, or alternatively the intervention group) and group \\(C\\) will be given the control (they are the control group or control arm). Suppose that we have \\(n\\) patients in group \\(C\\), and \\(m\\) in group \\(T\\). The primary outcome variable \\(X\\) is normally distributed with mean \\(\\mu\\) in group C (the control group) and mean \\(\\mu+\\tau\\) in group T (the intervention group), and common standard deviation \\(\\sigma\\). So \\[\\begin{align*} X &amp; \\sim N\\left(\\mu, \\sigma^2\\right) \\text{ in group }C\\\\ X &amp; \\sim N\\left(\\mu + \\tau, \\sigma^2\\right) \\text{ in group }T. \\end{align*}\\] We are testing the null hypothesis \\(H_0: \\tau=0\\) against the alternative hypothesis \\(H_1: \\tau\\neq{0}\\). Using the data obtained in the trial, we will be able to obtain sample means \\(\\bar{x}_C\\) and \\(\\bar{x}_T\\) from each group, and a pooled estimate of the standard deviation \\[ s = \\sqrt{\\frac{\\left(n-1\\right)s_C^2 + (m-1)s_T^2}{n+m - 2}}, \\] where \\(s_C\\) and \\(s_T\\) are the sample standard deviations for groups \\(C\\) and \\(T\\) respectively, for example \\[ s_C = \\sqrt{\\frac{\\sum\\limits_{i=1}^n{\\left(x_i - \\bar{x}_C\\right)^2}}{n-1}}. \\] Using these values we can compute \\[D = \\frac{\\bar{x}_T - \\bar{x}_C}{s\\sqrt{\\frac{1}{n} + \\frac{1}{m}}}\\] as a standardised measure of the effect \\(\\tau\\). Theorem 2.1 Under \\(H_0\\), and the model we’ve specified, \\(D\\) has a \\(t\\)-distribution with \\(n+m-2\\) degrees of freedom. Proof. Under \\(H_0\\) the \\(x_i\\) are iid \\(N\\left(\\mu,\\;\\sigma^2\\right)\\), and so \\[\\begin{align*} \\bar{x}_C &amp; \\sim{N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)}\\\\ \\bar{x}_T &amp; \\sim{N\\left(\\mu, \\frac{\\sigma^2}{m}\\right)} \\end{align*}\\] and therefore \\[ \\bar{x}_T - \\bar{x}_C \\sim{N \\left(0, \\sigma^2\\left[\\frac{1}{n} + \\frac{1}{m}\\right] \\right)}\\] and \\[ \\frac{\\bar{x}_T - \\bar{x}_C}{\\sigma \\sqrt{\\frac{1}{n}+\\frac{1}{m}}} \\sim{N\\left(0,1\\right)}.\\] We know that for \\(x_1,\\ldots,x_n,\\sim N\\left(\\mu,\\sigma^2\\right)\\) for some arbitrary \\(\\mu\\) and \\(\\sigma^2\\), \\[\\frac{1}{\\sigma^2}\\sum\\limits_{i=1}^n\\left(x_i - \\bar{x}\\right)^2 \\sim{\\chi^2_{n-1}},\\] and so we have \\[\\begin{align*} \\frac{n-1}{\\sigma^2}s_C^2 &amp; \\sim \\chi^2_{n-1}\\\\ \\frac{m-1}{\\sigma^2}s_T^2 &amp; \\sim \\chi^2_{m-1}\\\\ \\text{and} &amp;\\\\ \\frac{1}{\\sigma^2}\\left[\\left(n-1\\right)s_C^2 + \\left(m-1\\right)s_T^2\\right] &amp; = \\frac{n+m-2}{\\sigma^2}s^2\\\\ &amp;\\sim \\chi^2_{n+m-2}. \\end{align*}\\] The definition of a \\(t\\)-distribution is that if \\(Z\\sim N\\left(0,1\\right)\\) and \\(Y \\sim{\\chi^2_n}\\) then \\[X = \\frac{Z} {\\sqrt{\\frac{Y}{n}}} \\sim{t_n},\\] that is \\(X\\) has a \\(t\\) distribution with \\(n\\) degrees of freedom. Plugging in our \\(N\\left(0,1\\right)\\) variable for \\(Z\\) and our \\(\\chi^2_{n+m-2}\\) variable for \\(Y\\), we have \\[\\begin{align*} \\frac{\\frac{\\bar{x}_T - \\bar{x}_C}{\\sigma\\sqrt{\\frac{1}{n} + \\frac{1}{m}}}}{\\sqrt{\\left(\\frac{n+m-2}{\\sigma^2}s^2\\right) \\bigg/ \\left(n+m-2\\right)}} &amp; = \\frac{\\bar{x}_T - \\bar{x}_C}{\\sigma\\sqrt{\\frac{1}{n} + \\frac{1}{m}}} \\bigg/ \\frac{s}{\\sigma} \\\\ &amp; = \\frac{\\bar{x}_T - \\bar{x}_C}{s\\sqrt{\\frac{1}{n} + \\frac{1}{m}}} \\\\ &amp; = D \\end{align*}\\] and therefore \\(D\\) has a \\(t\\) distribution with \\(n+m-2\\) degrees of freedom. We can therefore use \\(D\\) as our test statistic; if \\(D\\) is such that \\[ |D| &gt; t_{n+m-2}\\left(\\alpha/2\\right)\\] where \\(t_{n+m-2}\\left(\\cdot\\right)\\) is the function such that \\(P\\left(T&gt;t_{df}\\left(\\xi\\right)\\right) = \\xi\\) when \\(T \\sim{t_{df}}\\) then we can reject \\(H_0\\). In practical terms, for more than around 40 degrees of freedom, the \\(t\\) distribution is indistinguishable from the normal distribution, and since it is rare to have fewer than 40 participants in an RCT, we use a normal approximation in what follows, and a difference is significant at the \\(100\\left(1-\\alpha\\right) \\%\\) level if \\(|D| &gt; z_{\\alpha/2}\\), where \\(z\\) are standard normal quantile values. For example, for \\(\\alpha=0.05\\) we have \\(z_{\\alpha/2} = 1.960\\), since the probability of a standard normal variable exceeding this value is 0.025. So, if we have run a trial, and have obtained \\(n\\) values of \\(X\\) from group \\(C\\) and \\(m\\) values of \\(X\\) from group \\(T\\), we can compute \\(D\\). If \\(D\\) lies outside the interval \\(\\left[-z_{\\alpha/2}, z_{\\alpha/2}\\right]\\) then we reject \\(H_0\\). This is equivalent to \\(\\bar{x}_T - \\bar{x}_C\\) falling outside the interval \\[\\left[-z_{\\alpha/2}s\\sqrt{\\frac{1}{n} + \\frac{1}{m}},\\; z_{\\alpha/2}s\\sqrt{\\frac{1}{n} + \\frac{1}{m}} \\right]. \\] Brief aside on notation We’ll see a lot of the notation \\(z_{\\alpha/2}\\) and similar, so to clarify: In R, we have \\(\\Phi\\left(z_{\\alpha/2}\\right) = \\texttt{pnorm}\\left(z_{\\alpha/2}\\right)\\) and \\(z_{\\alpha/2} = \\texttt{qnorm}\\left(\\Phi\\left(z_{\\alpha/2}\\right)\\right)\\). qnorm is the quantile and pnorm is the cumulative distribution function. So, for example \\[\\frac{\\alpha}{2} = 1 - \\Phi\\left(z_{\\alpha/2}\\right)\\] We have constructed our whole argument under the assumption that \\(H_0\\) is true, and that the probability of such a value is therefore \\(\\alpha\\). We want this probability to be small, since it constitutes an error; \\(H_0\\) is true, but our value of \\(D\\) (or the difference in means) leads us to reject \\(H_0\\). This is sometimes called the ‘type I’ error rate. But what if \\(H_0\\) is false? 2.4 Power: If \\(H_0\\) is false We have constructed things so that if \\(H_0\\) is true, we have a small probability of rejecting \\(H_0\\). But if \\(H_0\\) is false, and \\(\\tau\\neq{0}\\), we want our test to have a high probability of rejecting \\(H_0\\). Definition 2.4 The power of a test is the probability that we reject \\(H_0\\), given that \\(H_0\\) is false. The power function depends on the value of \\(\\tau\\) and is \\[\\Psi\\left(\\tau\\right) = \\Pr\\left(\\text{Reject } H_0\\mid{\\tau\\neq{0}}\\right) = 1 - \\beta.\\] We therefore also have \\[\\beta = \\Pr\\left(\\text{Fail to reject } H_0\\mid{\\tau\\neq{0}}\\right). \\] We call \\(\\beta\\) the type II error rate. If you find the notation confusing (as I do!) then it might be helpful to remember that both \\(\\alpha\\) and \\(\\beta\\) are error rates - probabilities of coming to the wrong conclusion. It is common to talk in terms of \\(\\alpha\\), the significance level, (which will be a low number, often 0.05) and of \\(1-\\beta\\), the power (which will be a high number, often 0.8). I’ve found though that it is not uncommon to find people refer to \\(\\beta\\) (rather than \\(1-\\beta\\)) as the power. If in doubt, keep in mind that we require \\(\\alpha,\\;\\beta \\ll 0.5\\). It is also common to use percentages: a significance level of \\(\\alpha=0.05\\) can also be referred to as “the 95% level”, and \\(\\beta=0.2\\) is the same as a “power of 80%”. When using percentages, we talk in terms of the amount of time we expect the test to come to the correct conclusion. If you notice any mistakes in these notes along these (or other!) lines, please point them out. Under \\(H_1\\), we have (approximately) \\[D \\sim{N\\left(\\frac{\\tau}{\\sigma\\lambda\\left(n,m\\right)}, 1\\right)},\\] where \\(\\lambda\\left(n,m\\right) = \\sqrt{\\frac{1}{n}+\\frac{1}{m}}\\) and \\[D = \\frac{\\bar{x}_T - \\bar{x}_C}{s\\sqrt{\\frac{1}{n} + \\frac{1}{m}}}.\\] Figure 2.4 shows the distribution of \\(D\\) under \\(H_0\\) and \\(H_1\\) for some arbitrary (non-zero) effect size \\(\\tau\\). The turquoise bar shows the ‘acceptance region’ of \\(H_0\\), ie. the range of observed values of \\(D\\) for which we will fail to reject \\(H_0\\). We see that this contains 95% of the area of the \\(H_0\\) distribution (we have set \\(\\alpha = 0.05\\) here), so under \\(H_0\\), we have a 0.95 probability of observing a value of \\(D\\) that is consistent with \\(H_0\\). This could easily generalise to another value of \\(\\alpha\\). Figure 2.4: The distribution of \\(D\\) under both \\(H_0\\) and \\(H_1\\) for some arbitrary values of effect size, population variance, \\(n\\) and \\(m\\), with the region in which we fail to reject \\(H_0\\) shown by the turquoise bar and the red shading. However, if \\(H_1\\) is true, and \\(\\tau\\neq{0}\\), there is a non-zero probability of observing a value of \\(D\\) that would lead us to fail to reject \\(H_0\\). This is shown by the area shaded in red, and it has area \\(\\beta\\). One minus this area (ie. the area under \\(H_1\\) that leads us to reject \\(H_0\\)) is the power, \\(1-\\beta\\). We can see that if the distributions have better separation, as in Figure 2.5, the power becomes greater. This can be as a result of a larger \\(\\tau\\), a smaller \\(\\sigma\\) or a smaller \\(\\lambda\\) (therefore larger \\(m\\) and/or \\(n\\)). Figure 2.5: The distribution of D under both \\(H_0\\) and \\(H_1\\) for some arbitrary values of effect size, population variance, \\(n\\) and \\(m\\), with the region in which we fail to reject \\(H_0\\) shown by the turquoise bar and the red shading. For given values of \\(\\alpha\\), \\(\\sigma\\) and \\(\\lambda\\left(n,m\\right)\\), we can calculate the power function in terms of \\(\\tau\\) by finding the area of the distribution of \\(D\\) under \\(H_1\\) for which we accept \\(H_1\\). \\[\\begin{equation} \\Psi\\left(\\tau\\right) = 1-\\beta = \\left[1 - \\operatorname{\\Phi}\\left(z_{\\frac{\\alpha}{2}} - \\frac{\\tau}{\\sigma\\lambda}\\right)\\right] + \\operatorname{\\Phi}\\left(-z_{\\frac{\\alpha}{2}} - \\frac{\\tau}{\\sigma\\lambda}\\right) \\tag{2.1} \\end{equation}\\] The first term in Equation (2.1) is the area in the direction of \\(\\tau\\). In Figures 2.4 and 2.5 this is the region to the right of the interval for which we fail to reject \\(H_0\\), ie. where \\[D &gt; z_{\\frac{\\alpha}{2}}.\\] The second term in Equation (2.1) represents the area away from the direction of \\(\\tau\\), ie. a value of \\(D\\) such that \\[ D &lt; - z_{\\frac{\\alpha}{2}},\\] assuming without loss of generality that \\(\\tau&gt;0\\). Figure 2.6 shows the power function \\(\\Psi\\left(\\tau\\right)\\) for \\(\\tau\\) in units of \\(\\sigma\\) (or you could think of this as for \\(\\sigma=1\\)), for three different pairs of values of \\(n\\) and \\(m\\) (remember that these enter the power function via \\(\\lambda\\)) with \\(\\alpha=0.05\\). We see that in general the power is higher for larger sample sizes, and that of the two designs where \\(n+m=200\\), the balanced one with \\(n=m=100\\) achieves the greatest power. In general, the probability of rejecting \\(H_0\\) increases as \\(\\tau\\) moves away from zero. Notice also that all the curves pass through the point \\(\\tau=0,\\,\\beta=0.05\\). Since \\(\\tau=0\\) corresponds to \\(H_0\\) being true, it makes sense that the probability of rejecting the \\(H_0\\) is the significance level \\(\\alpha\\). Figure 2.6: Power curves for various values of \\(n\\) and \\(m\\), with effect size in units of standard deviation, given a type I error rate of 0.05. It is common to think of the effect size in units of \\(\\sigma\\), as we have done here. This makes results more intuitive, since we don’t need to have a good knowledge of the actual outcome variable to know what is a small or large effect size. It is also helpful in situations where the population standard deviation is not well understood, since the trial can be planned with this sort of effect size in mind. To denote the effect size in units of \\(\\sigma\\), we will write \\(\\tau_\\sigma\\), although in practice it is more usual to give both the same notation. In a medical setting we will often have an estimate for \\(\\sigma\\) (for example from previous studies). 2.5 A sample size formula Equation (2.1) allows us to find any one of \\(\\tau_\\sigma,\\,\\alpha,\\,\\beta\\) and \\(\\lambda\\left(n,m\\right)\\) given values for the others. Values for \\(\\alpha\\) and \\(\\beta\\) are often specified by those planning the trial as around \\(\\alpha \\in \\left[0.01,0.05\\right],\\,1-\\beta\\in\\left[0.8,0.9\\right]\\). The remaining two values, \\(\\tau_\\sigma\\) and \\(\\lambda\\left(n,m\\right)\\) are generally settled using one or both of the following questions: Given our budget constraints, and their implications for \\(n\\) and \\(m\\), what is the smallest value of \\(\\tau_\\sigma\\) we can achieve? What is the smallest value of \\(\\tau_\\sigma\\) that would be clinically useful to detect, and what value of \\(\\lambda\\left(n,m\\right)\\) do we need in order to achieve it? An important quantity is therefore the minimum detectable effect size, which we will denote \\(\\tau_M\\). Definition 2.5 The minimum detectable effect size \\(\\tau_M\\) for a particular trial is the smallest value of effect size that is able to be detected with power \\(1-\\beta\\) and at significance level \\(\\alpha\\) (for some specified values of \\(\\alpha,\\;\\beta\\)). Note that we will not definitely detect an effect of size \\(\\tau_M\\), if it exists; by construction, we will detect it with probability \\(1-\\beta\\). If \\(|\\tau| &gt; |\\tau_M|\\) (ie. the true effect size is further from zero than \\(\\tau_M\\) is) then the probability of detecting it will be greater than \\(1-\\beta\\). If \\(|\\tau| &lt; |\\tau_M|\\) then the probability of detecting it will be less than \\(1-\\beta\\). Although we could solve Equation (2.1) numerically, in practice we use an approximation. The second term, representing observed values of \\(D\\) that are far enough away from 0 in the opposite direction from the true \\(\\tau\\) to lead us to reject \\(H_0\\) is so negligible as to be able to be discounted entirely. Indeed, if we were to observe such a value of \\(D\\), we would come to the wrong conclusion about \\(\\tau\\). Therefore, Equation (2.1) becomes \\[\\begin{equation} \\Psi\\left(\\tau\\right) = 1-\\beta = \\left[1 - \\operatorname{\\Phi}\\left(z_{\\frac{\\alpha}{2}} - \\frac{\\tau_M}{\\sigma\\lambda}\\right)\\right]. \\tag{2.2} \\end{equation}\\] Because \\(\\operatorname{\\Phi}\\left(z_\\beta\\right) = 1 - \\beta\\) (by definition) and \\(\\operatorname{\\Phi}\\left(-z\\right) = 1 - \\operatorname{\\Phi}\\left(z\\right)\\) we can write this as \\[ \\operatorname{\\Phi}\\left(z_\\beta\\right) = \\operatorname{\\Phi}\\left(\\frac{\\tau_M}{\\sigma\\lambda} - z_{\\frac{\\alpha}{2}}\\right), \\] where \\(\\tau_M\\) is our minimum detectable effect size. Because of the monotonicity of \\(\\operatorname{\\Phi}\\left(\\cdot\\right)\\), this becomes \\[\\begin{equation} \\begin{aligned} z_\\beta &amp; = \\frac{\\tau_M}{\\sigma\\lambda} - z_{\\frac{\\alpha}{2}} \\\\ z_\\beta + z_{\\frac{\\alpha}{2}} &amp; = \\frac{\\tau_M}{\\sigma\\lambda}. \\end{aligned} \\tag{2.3} \\end{equation}\\] Because we want to think about sample sizes, we rewrite this further. It is most common to perform trials with \\(n=m=N\\) participants in each group, in which case \\[ \\lambda\\left(n,m\\right) = \\sqrt{\\frac{2}{N}}\\] and Equation (2.3) rearranges to \\[\\begin{equation} N = \\frac{2\\sigma^2\\left(z_\\beta + z_{\\frac{\\alpha}{2}}\\right)^2}{\\tau_M^2}. \\tag{2.4} \\end{equation}\\] Example 2.1 (from Zhong 2009) A trial is being planned to test whether there is a difference in the efficacy of ACEII antagonist (a new drug) and ACE inhibitor (the standard drug) for the treatment of primary hypertension (high blood pressure). The primary outcome variable is change in sitting diastolic blood pressure (SDBP, mmHg) compared to a baseline measurement taken at the start of the trial. The trial should have a significance level of \\(\\alpha=0.05\\) and a power of \\(1-\\beta = 0.8\\), with the same number of participants in each group. The minimum clinically important difference is \\(\\tau_M = 3 \\text{ mmHg}\\) and the pooled standard deviation is \\(s = 8 \\text{ mmHg}\\). Therefore, using equation (2.4) the sample size should be at least \\[\\begin{align*} N &amp; = \\frac{2\\times{8}^2\\left(0.842 + 1.96\\right)^2}{3^2}\\\\ &amp; = 111.6, \\end{align*}\\] and therefore we need at least 112 participants in each trial arm. References Zhong, Baoliang. 2009. “How to Calculate Sample Size in Randomized Controlled Trial?” Journal of Thoracic Disease 1 (1): 51. "],["alloc.html", "3 Allocation 3.1 Bias 3.2 Allocation methods 3.3 Incorporating baseline measurements 3.4 Problems around allocation", " 3 Allocation Once we’ve decided how many participants we need in our trial, we need to determine how they will each be assigned to a trial arm. This is process is known as allocation (or sometimes as randomization). Before we think about methods for allocation, we are going to spend some time talking about bias. 3.1 Bias In statistics, bias is a systematic tendency for the results of our analysis to be different from the true value. We see this particularly when we are using sample data to estimate a parameter. We will revisit what we have learned in previous courses about bias before going on to see how it affects RCTs. Definition 3.1 (Bias of an estimate) Suppose that \\(T\\) is a statistic calculated to estimate a parameter \\(\\theta\\). The bias of \\(T\\) is \\[E\\left(T\\right) - \\theta.\\] If the bias of \\(T\\) is zero, we say that \\(T\\) is an unbiased estimator of \\(\\theta\\). An example you will have seen before is the standard deviation. If we have some data \\(x_1,\\,\\ldots,x_n\\) that are IID \\(N\\left(\\mu,\\,\\sigma^2\\right)\\), we can calculate the sample variance \\[ s^2 = \\frac{1}{n}\\sum\\limits_{i=1}^n\\left(x_i - \\bar{x}\\right)^2 .\\] In this case, \\(E\\left(s^2\\right) \\neq {\\sigma^2}\\) (you’ve probably seen this proved so we’re not going to prove it now), and \\(s^2\\) is a biased estimator of \\(\\sigma^2\\). However, we know that \\[E \\left(\\frac{n}{n-1}s^2\\right) = \\sigma^2,\\] and therefore we can apply this correction to the sample variance \\(s^2\\) to produce an unbiased estimate of the population variance \\(\\sigma^2\\). Here, the sample are representative of the population, but the size of the sample leads to some bias. Now, suppose our sample \\(x_1,\\ldots,x_n\\) were drawn from \\(N\\left(\\mu,\\sigma^2\\right)\\), but were not independent of one another. Then, neither our estimator \\(s^2\\), nor our bias-corrected estimator \\(\\frac{n}{n-1}s^2\\) would have expected value \\(\\sigma^2\\). Furthermore, we cannot use our sample \\(x_1,\\ldots,x_n\\) to produce an unbiased estimator of \\(\\sigma^2\\), or even of the mean \\(\\mu\\). This scenario is much closer to what we mean when we talk about bias in a clinical trial setting. Suppose we are testing some new treatment \\(T\\) against the standard \\(C\\). We measure some outcome \\(X\\) for each patient, and our hypothesis is that \\(X\\) behaves differently for those in the treatment group than for those in the control group. It is common practice to express this additively, \\[E\\left(X\\right) = \\mu + \\tau,\\] where \\(\\tau\\) is our treatment effect, which we can estimate using the difference in the groups’ means, \\(\\bar{X}_T - \\bar{X}_C\\). Our null hypothesis is that \\(\\tau = 0\\), and our alternative hypothesis is that \\(\\tau\\neq{0}\\), and therefore an estimate of \\(\\tau\\) from our data is very important! Put equivalently, it is important that there is no bias in our estimates of \\(\\bar{X}_C\\) and \\(\\bar{X}_T\\). Usually, what this comes down to is that the assumption that the data are independent, identically distributed random variables from the relevant distributions (which we have already relied on a lot for our sample size calculations) has been violated in some way. Example 3.1 Historically, women and the elderly are underrepresented in clinical trials (Cottingham and Fisher (2022)) and results are often translated from young or middle aged healthy men to these other groups (Vitale et al. (2017)). This isn’t reasonable, since women have very different hormonal activity from men, causing them to often react differently to drugs compared to men involved in the trial. The standard dose (based on trials with mostly male participants) can also be too high for many women. The complicated nature of women’s hormones is sometimes even given as a reason for not including them in the trial. Women and elderly people are also both more likely to have adverse effects to drugs in some fields. There are also ethical reasons behind the low numbers of women in trials, especially phase I and phase II trials. If a woman is possibly pregnant (and trials tend to be extremely cautious in deciding who might be pregnant!) then they are quite often excluded, in order to protect the (actual or hypothetical) fetus. Indeed, in 1977 the Food and Drug Administration (FDA) in the US recommended that women be excluded from phase I and II trials (Health (2023)) as a result of some severe cases of fetuses being harmed by drugs (especially Thalidamide) . This means that even some very mainstream drugs, for example antihistamines (Kar et al. (2012)), haven’t been tested for safety/efficacy during pregnancy, as well as some (for example HIV treatments) that would be of huge benefit to many many pregnant women. This article is an interesting read if you would like to know more. In the above example, the trial cohort is very deliberately (and arguably sometimes defensibly) not representative of the target population. However, bias can creep into trials in a number of ways. 3.1.1 Where does bias come from? Having established that bias is a serious issue in clinical trials, we will think about several sources of bias. Some of these we will elaborate on as we get to the relevant part of methodology. Most sources of bias creep in during the allocation or selection phase. Selection bias Selection bias occurs when certain patients or subjects are systematically more (or less) likely be entered into the trial because of the treatment they will receive. In a properly run trial this isn’t possible, because it is only after a participant has been recruited that their treatment is chosen. If a medical professional is not comfortable with a particular patient potentially receiving one of the possible treatments, then that patient should not be entered into the trial at all. If there are many such [technically eligible] patients, then this might cause the estimated treatment effect to be worryingly far from the true population treatment effect, since the recruited group of participants would not be very representative of the true population (this is not technically selection bias, but it comes from the same problem). It may happen that the doctor knows which treatment a patient would be given, for example if the allocation follows some deterministic pattern, or is fully known to the doctor in advance. Consciously or subconsciously this knowledge may influence the description they give to potential participants, and this in turn may affect which patients sign up, and the balance of the groups. In practice there should be various safeguards against this situation. Allocation bias Mathematically, allocation bias is similar to selection bias, but instead of coming from human ‘error’, it arises from the random process of allocation. Suppose a trial investigates a drug that is likely to have a much stronger effect on male patients than on female patients. The cohort of recruited participants are randomised into treatment and control groups, and it happens that there is a much smaller proportion of female patients in the treatment group than in the control group. This will distort the estimated treatment effect. We will investigate various strategies for randomization designed to address this issue for known factors. Example 3.2 This example is framed in terms of selection bias, but applies equally to allocation bias Suppose we run a trial comparing a surgical (S) and a non-surgical (N) treatment for some condition. Patients who are eligible are given the opportunity to join the trial by a single doctor. The severity of the disease is graded as 1 (less serious) or 2 (more serious) for each patient. Across the full group of patients, proportion \\(\\lambda\\) have severity 1 and proportion \\(1-\\lambda\\) have severity 2. Our primary outcome is survival time, \\(X\\), which depends on the severity of disease: \\[\\begin{align*} E\\left(X\\mid{1}\\right) &amp; = \\mu_1\\\\ E\\left(X\\mid{2}\\right) &amp; = \\mu_2 \\end{align*}\\] and we assume \\(\\mu_1&gt;\\mu_2\\). For the overall trial group, for untreated patients we have \\[ E\\left(X\\right) = \\mu = \\lambda \\mu_1 + \\left(1-\\lambda\\right)\\mu_2.\\] Suppose that for treatment group \\(N\\), the expected survival time increase by \\(\\tau_N\\), and similarly for group \\(S\\), so that we have \\[\\begin{align*} E\\left(X\\mid{N,1}\\right) &amp; = \\mu_1 + \\tau_N\\\\ E\\left(X\\mid{N,2}\\right) &amp; = \\mu_2 + \\tau_N\\\\ E\\left(X\\mid{S,1}\\right) &amp; = \\mu_1 + \\tau_S\\\\ E\\left(X\\mid{S,2}\\right) &amp; = \\mu_2 + \\tau_S. \\end{align*}\\] If all patients were admitted with equal probability to the trial (ie. independent of the severity of their disease) then the expected survival time for group \\(N\\), \\(E\\left(X\\mid{N}\\right)\\), would be \\[\\begin{align*} E\\left(X\\mid{1,N}\\right)P\\left(1\\mid{N}\\right) + E\\left(X\\mid{2,N}\\right)P\\left(2\\mid{N}\\right)&amp; = \\left(\\mu_1 + \\tau_N\\right)\\lambda + \\left(\\mu_2+\\tau_N\\right)\\left(1-\\lambda\\right)\\\\ &amp; = \\mu + \\tau_N. \\end{align*}\\] Similarly, the expected survival time in group \\(S\\) would be \\(\\mu+\\tau_S\\), and the treatment effect difference between the two would be \\(\\tau = \\tau_N - \\tau_S\\) and the trial is unbiased. Suppose that although all eligible patients are willing to enter the trial, the doctor is reticent to subject patients with more severe disease (severity 2) to the surgical procedure. This is reflected in the way they explain the trial to each patient, particularly those with severity 2 whom the doctor knows will be assigned to group \\(S\\). In turn this leads to a reduced proportion \\(q = 1-p\\) of those with severity 2 assigned to surgery entering the trial (event \\(A\\)): \\[\\begin{align*} P\\left(A\\mid{N,1}\\right) = P\\left(A\\mid{S,1}\\right) = P\\left(A\\mid{N,2}\\right) &amp; = 1 \\\\ P\\left(A\\mid{S,2}\\right) &amp; = 1-p = q. \\end{align*}\\] Since our analysis is based only on those who enter the trial, our estimated treatment effect will be \\[E\\left(X\\mid{A, N}\\right) - E\\left(X\\mid{A, S}\\right). \\] We can split these according to disease severity, so that \\[E\\left(X\\mid{A,N}\\right) = E\\left(X\\mid{A,N,1}\\right)P\\left(1\\mid{A,N}\\right) + E\\left(X\\mid{A,N,2}\\right)P\\left(2\\mid{A,N}\\right) \\] and similarly for group \\(S\\). We can calculate \\(P\\left(1\\mid{A,N}\\right)\\) using Bayes’ theorem, \\[\\begin{align*} P\\left(1\\mid{A,N}\\right) &amp; = \\frac{P\\left(A\\mid{1,N}\\right)P\\left(1\\mid{N}\\right)}{P\\left(A\\mid{N}\\right)}\\\\ &amp; = \\frac{P\\left(A\\mid{1,N}\\right)P\\left(1\\mid{N}\\right)}{P\\left(A\\mid{N,1}\\right)P\\left(1\\mid{N}\\right) + P\\left(A\\mid{N,2}\\right)P\\left(2\\mid{N}\\right)} \\\\ &amp;= \\frac{1\\times{\\lambda}}{1\\times {\\lambda} + 1 \\times{\\left(1-\\lambda\\right)}}\\\\ &amp; = \\lambda. \\end{align*}\\] Therefore we also have \\(P\\left(2\\mid{A,N}\\right) = 1 -P\\left(1\\mid{A,N}\\right) = 1-\\lambda\\). Following the same process for group \\(S\\), we arrive at \\[\\begin{align*} P\\left(1\\mid{A,S}\\right) &amp; = \\frac{P\\left(A\\mid{1,S}\\right)P\\left(1\\mid{S}\\right)}{P\\left(A\\mid{S}\\right)}\\\\ &amp; = \\frac{P\\left(A\\mid{1,S}\\right)P\\left(1\\mid{S}\\right)}{P\\left(A\\mid{S,1}\\right)P\\left(1\\mid{S}\\right) + P\\left(A\\mid{S,2}\\right)P\\left(2\\mid{S}\\right)} \\\\ &amp; = \\frac{\\lambda}{\\lambda + q\\left(1-\\lambda\\right)}, \\end{align*}\\] which we will call \\(b\\). Notice that \\(P\\left(2\\mid{S}\\right)= 1-\\lambda\\), since it is not conditional on actually participating in the trial. Therefore, \\[\\begin{align*} E\\left(X\\mid{A,N}\\right) &amp; = E \\left(X\\mid{N,1}\\right)P\\left(1\\mid{A,N}\\right) + E \\left(X\\mid{N,2}\\right)P\\left(2\\mid{A,N}\\right) \\\\ &amp; = \\left(\\mu_1 + \\tau_N\\right)\\lambda + \\left(\\mu_2 + \\tau_N\\right)\\left(1-\\lambda\\right) \\\\ &amp; = \\lambda\\mu_1 + \\left(1-\\lambda\\right)\\mu_2 + \\tau_N \\end{align*}\\] and \\[\\begin{align*} E\\left(X\\mid{A,S}\\right) &amp; = E \\left(X\\mid{S,1}\\right)P\\left(1\\mid{A,S}\\right) + E \\left(X\\mid{S,2}\\right)P\\left(2\\mid{A,S}\\right) \\\\ &amp; = \\left(\\mu_1 + \\tau_S\\right)b + \\left(\\mu_2 + \\tau_S\\right)\\left(1-b\\right) \\\\ &amp; = b\\mu_1 + \\left(1-b\\right)\\mu_2 + \\tau_S. \\end{align*}\\] From here, we can calculate the expected value of the treatment effect \\(\\tau\\) as (substituting our equation for \\(b\\) and rearranging): \\[\\begin{align*} E\\left(X\\mid{A,N}\\right) - E\\left(X\\mid{A,S}\\right) &amp; = \\tau_N - \\tau_S + \\left(\\lambda - b\\right)\\left(\\mu_1 - \\mu_2\\right) \\\\ &amp; = \\tau_N - \\tau_S - \\frac{p\\lambda\\left(1-\\lambda\\right)\\left(\\mu_1 - \\mu_2\\right)}{\\lambda + q\\left(1-\\lambda\\right)}, \\end{align*}\\] where the third term represents the bias. Notice that if \\(q=1-p = 1\\), then there is no bias. There is also no bias if \\(\\mu_1 = \\mu_2\\), ie. if there is no difference between the disease severity groups in terms of survival time. Assuming \\(\\mu_1 - \\mu_2 &gt;0\\), then the bias term is positive and \\[E\\left(X\\mid{A,N}\\right)- E\\left(X\\mid{A,S}\\right) &lt; \\tau_N - \\tau_S.\\] If \\(N\\) is the better treatment, then \\(\\tau_N - \\tau_S&gt;0\\) and the bias will cause the trial to underplay the treatment effect. Conversely, if \\(S\\) is better, then \\(\\tau_N-\\tau_S&lt;0\\) and the trial will exaggerate the treatment effect. Essentially, this is because more severely ill patients have been assigned to \\(N\\) than to \\(S\\), which reduces the average survival time for those in group \\(N\\). Assessment bias Measurements are made on participants throughout the trial. These measurements will often be objective, for example the patients’ weight, or concentration of blood sugar. However, some types of measurement are much more subject to the individual practitioner assessing the patient. For example, many skin conditions are assessed visually, for example estimating the proportion of the body affected. Measuring quantities such as quality of life or psychological well-being involve many subjective judgements on the part of both patient and clinician. Clearly it is ideal for both the patient and the clinician not to know which arm of the trial the patient was part of (this is known as a double blind trial). For treatments involving drugs, this is usually straightforward. However, for surgical interventions it is often impossible to keep a trial ‘blind’, and for interventions involving therapy (for example cognitive behavioural therapy) it is impossible for the patient to be unaware. In this situation, it is possible for the patient or clinician’s judgement to be affected by their knowledge of the allocation, thus affecting the estimated treatment effect. Slight aside: publication bias In most areas of science, including clinical trials, the ultimate aim is to affect practice. This is usually done by publishing a write-up of the trial, including its design, methods, analysis and results, and publishing that in a [medical] journal. These are peer-reviewed, which means that experts from the relevant field are ask to review submitted papers, and either reject or accept them (usually conditional on some revision). These reviewers advise the editor of the journal, who ultimately decides whether or not the paper will be published. There is compelling evidence that papers reporting positive / conclusive results are more likely to be published than papers about [viable] trials that ultimately fail to reject the null hypothesis. As we know, in most cases if the null hypothesis is rejected this is indicative that there is a true treatment difference. However, sometimes by random chance a trial will detect a difference even when there isn’t one (approximately 5% of the time if \\(\\alpha=0.05\\)). If these papers are disproportionately likely to be published, the body of literature will not reflect the truth, and there may be serious implications for practice. This is a huge issue in the pharmaceutical industry, and one from which we can’t escape. If you’d like to learn more about it the book ‘Bad Pharma’ by Goldacre (2012) is an excellent source. Measures are being taken to prevent this: for example, leading medical journal The Lancet insists that any clinical trial related paper is registered with them before the first participant has been recruited, with details of the design and statistical analysis plan. This is then reviewed before the trial begins. 3.1.2 Implications for allocation Historically (and probably still, to an extent), clinical trials have not necessarily used random allocation to assign participants to groups. Altman and Bland (1999) gives an overview of why this has led to bias, and gives some examples. Sometimes analyses compare groups in serial, so that \\(N_A\\) patients one year (say) form the control group, and \\(N_B\\) patients in a subsequent year, who are given treatment \\(B\\), form the intervention group. In this scenario it is impossible to control for all other changes that have occurred with time, and this leads to a systematic bias, usually in favour of treatment \\(B\\). Given the need for contemporary control participants, the question becomes how to assign participants to each group. If the clinician is able to choose who receives which treatment, or if each patient is allowed to choose or refuse certain treatments, this is almost certain to introduce bias. This is avoided by using random allocation. There are two important aspects to the allocation being random that we will draw attention to. Every patient should have the same probability of being assigned to each treatment group. The treatment group for a particular patient should not be able to be predicted. Point 1 is important because, as we have already mentioned, the statistical theory we use to plan and analyse the trial is based on the groups being random samples from the population. Point 2 is important to avoid biases that come through the assignment of a particular patient being known either in advance or after the fact. There are some approaches that ‘pass’ the first point, but fail at the second. As well as strict alternation (\\(ABABAB\\ldots\\)), some such methods use patient characteristics such as date of birth or first letter of surname, which is not related to the trial outcome, but which enables allocations to be predicted. We will now explore some commonly used methods of allocation. We will usually assume two equally sized groups, \\(A\\) and \\(B\\), but it is simple to generalize to three or more groups, or to unequal allocation. 3.2 Allocation methods 3.2.1 Simple random allocation Perhaps intuitively the most simple method is a ‘toin coss’, where each participant has a probability 0.5 of being placed in each group. As participants arrive, assignment \\(C\\) or \\(T\\) is generated (with equal probability). Statistically, this scheme is ideal, since it generates the random sample we need, and the assignment of each participant is statistically independent of that of all other participants. It also doesn’t require a ‘master’ randomisation; several clinicians can individually assign participants to treatment groups in parallel and the statistical properties are maintained. This method is used effectively in many large trials, but for small trials it can be statistically problematic. The main reason for this is chance imbalance of group sizes. Suppose we have two groups, \\(T\\) of size \\(N_T\\) and \\(C\\) of size \\(N_C\\), with \\(N_T + N_C = 2n\\). Patients are allocated independently with equal probability, which means \\[N_C \\sim \\operatorname{Bi}\\left(2n,\\frac{1}{2}\\right), \\] and similar for \\(N_T\\). If the two groups are of unequal size, the larger will be of some size \\(N_{max}\\) between \\(n\\) and \\(2n\\), such that for \\(r = n+1,\\,\\ldots,\\,2n,\\) \\[\\begin{align*} P\\left(N_{max} = r\\right) &amp; = P\\left(N_C = r\\right) + P\\left(N_T = r\\right) \\\\ &amp; = 2\\binom{2n}{r}\\left(\\frac{1}{2}\\right)^{2n}. \\end{align*}\\] The probability that \\(N_C = N_T = n\\) is \\[ P\\left(N_T = N_C = n\\right)= \\binom{2n}{n}\\left(\\frac{1}{2}\\right)^{2n}. \\] These probabilities are shown in Figure 3.1. We can see that this method leads to very unequal groups relatively easily; with \\(n=15\\), \\(P\\left(N_{max}\\geq 20\\right) = 0.099\\), so there is around a one in ten chance that one group will be double or more the size of the other. Figure 3.1: The probability distribution of largest group size for n=15. As we have seen when thinking about sample sizes in Section 2.4, this will reduce the power \\(\\Psi\\) of the trial, since it depends on \\(\\lambda\\left(N_C,\\,N_T\\right) = \\sqrt{\\frac{1}{N_C} + \\frac{1}{N_T}}\\). In this chapter, and in the computer practical on allocation, we will study the behaviour of various allocation methods by implementing them many times. This gives us an idea of how variable the results are, especially in terms of being likely to introduce bias or reduce power. In almost all real trials, patients are allocated and begin treatment as they arrive, and this may happen over the course of weeks or months. The allocation that is generated is the final allocation. For larger trials, this imbalance will be less pronounced, for example Figure 3.2 shows the same for \\(n=200\\). Figure 3.2: The probability distribution of largest group size for n=200. In this case \\(P\\left(N_{max} \\geq 220\\right)=0.051\\), so the chance of highly imbalanced groups is much lower. However, we may want to achieve balance on some factor thought to be important, for example sex, age group or disease state, and in this case there may be small numbers even in a large trial. We saw in the sample size section that the greatest power is achieved when group sizes are equal, since this minimises the function \\[\\lambda\\left(n,m\\right) = \\sqrt{\\frac{1}{n}+\\frac{1}{m}}.\\] However, with simple random sampling we can’t guarantee equal group sizes. Example 3.3 Suppose we are designing a trial to have \\(\\alpha=0.05\\), and our minimum detectable effect size is such that \\(\\frac{\\tau_M}{\\sigma}=1\\). If 30 participants are recruited, then we can calculate the power of the study using methods from Chapter 2: \\[1-\\beta = \\Phi\\left(\\sqrt{\\frac{n_T\\,n_C}{30}} - 1.96\\right). \\] The first term in the standard normal CDF comes from the fact that \\[\\left[\\lambda\\left(n,m\\right)\\right]^{-1} = \\sqrt{\\frac{nm}{n+m}} .\\] If we have equal group sizes \\(n_T=n_C=15\\), then the power achieved is 78%. If the group sizes are 10 and 20, we have a power of 73%. If the group sizes are 6 and 24, the power goes down to 59%. So, as we saw when looking at power, we don’t lose too much if the group sizes are 2:1, but a more pronounced imbalace has resulted in a much more noticeable loss. There may be other disadvantages to having such imbalance, for example increased costs, or a reduction in the amount of information gained about side effects. If this imbalance can be avoided, it should be. 3.2.2 Random permuted blocks One commonly used method to randomly allocate participants while avoiding imbalance is to use random permuted blocks (RPBs). With RPBs we randomly generate the allocation in blocks of some predetermined size. If the blocks have size \\(2m\\), and there are two groups then there are \\[\\binom{2m}{m},\\] but this method can be adapted to more than two groups and to unequal group size. Example 3.4 If we have two groups, \\(A\\) and \\(B\\), then there are six blocks of length 4 containing two \\(A\\)s and two \\(B\\)s \\[ \\begin{aligned} 1.&amp; AABB\\\\ 2.&amp; ABAB\\\\ 3.&amp; ABBA\\\\ 4.&amp; BAAB\\\\ 5.&amp; BABA\\\\ 6.&amp; BBAA. \\end{aligned} \\] We can also randomly generate a sequence of numbers from \\(\\left\\lbrace 1, 2, 3, 4, 5, 6 \\right\\rbrace\\), where each number has equal probability. This sequence will correspond to a sequence in \\(A\\) and \\(B\\) with four times the length. In this method, each patient is equally likely to receive \\(A\\) and \\(B\\), but there will never be a difference of more than two between the size of the two groups. For example, suppose the sequence begins \\(2,1,3,6,\\ldots\\). Replacing each number by its block, we have \\(ABAB\\;AABB\\;ABBA\\;BBAA\\;\\ldots\\). One serious disadvantage of this method is that if the block size is fixed, and the doctors involved in the trial know which participants have received which treatments (which is unavoidable in cases such as surgery), then the allocation for some patients can be perfectly predicted. For blocks of size four this is true for the fourth in every block, and for the third and fourth if the first two were the same. This means that selection bias may be a problem in more than 25% of participants, which is deemed unacceptable; indeed, it fails our second point about randomization. 3.2.2.1 RPBs with random block length The issue above can be circumvented by not only randomly choosing from a selection of blocks, but also randomly choosing the length of the block. For example, there are \\[ \\binom{6}{3} = 20\\] possible blocks of size 6. Instead of always selecting from the six possible 4-blocks, a sampling scheme can be as follows. A random number \\(X\\) is drawn from \\(\\left\\lbrace 4,6\\right\\rbrace\\) to select the block length. A second random number \\(Y\\) is drawn from 1 to 6 (if the block length is four) or 1 to 20 (if the block length is 6). The block corresponding to \\(Y\\) is chosen and participants assigned accordingly. If more participants are needed, go back to step 1. As well as ensuring that patients are equally likely to receive treatments \\(A\\) and \\(B\\), and that \\(N_A\\) and \\(N_B\\) can never differ by more than three, this method hugely reduces the possibility of enabling selection bias. The assignment of a patient can only be perfectly predicted if the difference is three, and this happens only for two of the twenty blocks of length six. 3.2.3 Biased coin designs and urn schemes It may be that we prefer a method that achieves balance while retaining the pure stochasticity of simple random sampling. An advantage of RPBs was that once the sequence was generated, no computing power was needed. However, it is safe now to assume that any hospital pharmacy, nurse’s station, GP office or other medical facility will have a computer with access to the internet (or some internal database), and therefore more sophisticated methods are available. It is also very likely that all trial data may be stored on some central database, and so methods that rely on knowing the allocation so far (albeit in some encrypted form) should be possible even if there are multiple clinicians and sites involved. Biased coin designs and urn schemes both work by adjusting the probabilities of allocation according to balance of the design so far, such that a participant is less likely to be assigned to an over-represented group. 3.2.3.1 Biased coin designs The biased coin design was introduced by Efron (1971), with the aim of ensuring balance whilst not becoming vulnerable to various forms of experimental bias. Efron (1971) suggested the biased coin design be used within categories (eg. age group, sex, disease state etc.), but in this section we will think about the whole cohort (the maths for a subgroup would be the same). Suppose we are using a biased coin design for a trial to compare two treatments, \\(T\\) and \\(C\\). At the point where some number \\(n\\) (not the total trial cohort) have been allocated, we can use the notation \\(N_T\\left(n\\right)\\) for the number of participants allocated to treatment \\(T\\), and \\(N_C\\left(n\\right)\\) for the number of participants allocated to treatment \\(C\\). Using these, we can denote the imbalance in treatment numbers by \\[ D\\left(n\\right) = N_T\\left(n\\right) - N_C\\left(n\\right) = 2N_T\\left(n\\right) - n.\\] We use the imbalance \\(D\\left(n\\right)\\) to alter the probability of allocation to each treatment in order to restore (or maintain) balance in the following way: If \\(D\\left(n\\right)=0\\), allocate patient \\(n+1\\) to treatment \\(T\\) with probability \\(\\frac{1}{2}\\). If \\(D\\left(n\\right)&lt;0\\), allocate patient \\(n+1\\) to treatment \\(T\\) with probability \\(P\\). If \\(D\\left(n\\right)&gt;0\\), allocate patient \\(n+1\\) to treatment \\(T\\) with probability \\(1-P\\). where \\(P\\in\\left(\\frac{1}{2}, 1\\right)\\). Question: What would happen if \\(P=\\frac{1}{2}\\) or \\(P=1\\)? If, at some point in the trial, we have \\(\\lvert D\\left(n\\right)\\rvert = j\\), for some \\(j&gt;0\\), then we must have either \\[ \\lvert D\\left(n+1\\right)\\rvert = j+1 \\] or \\[ \\lvert D\\left(n+1\\right)\\rvert = j-1 .\\] Because of the way we have set up the scheme, \\[ p\\big(\\lvert D\\left(n+1\\right)\\rvert = j+1\\big) = 1-P \\] and \\[ p\\big(\\lvert D\\left(n+1\\right)\\rvert = j-1\\big) = P.\\] If \\(\\lvert D\\left(n\\right) \\rvert = 0\\), ie. the scheme is in exact balance after \\(n\\) allocations, then we must have \\(\\lvert D\\left(n\\right)\\rvert = 1\\). The absolute imbalances therefore form a simple random walk on the non-negative integers, with transition probabilities \\[ \\begin{aligned} P\\bigg(\\lvert D\\left(n+1\\right) \\rvert = 1 \\; \\bigg| \\;\\lvert D\\left(n\\right)\\rvert=0\\bigg)&amp; = 1\\\\ P\\bigg(\\lvert D\\left(n+1\\right) \\rvert = j+ 1 \\; \\bigg| \\; \\lvert D\\left(n\\right)\\rvert=j\\bigg)&amp; = 1 - P\\\\ P\\bigg(\\lvert D\\left(n+1\\right) \\rvert = j-1 \\; \\bigg| \\; \\lvert D\\left(n\\right)\\rvert=j\\bigg)&amp; = P \\end{aligned} \\] Figure 3.3 shows four realisations of this random walk with \\(P=0.667\\) (Efron’s preferred value). We see that sometimes the imbalance gets quite high, but in general it isn’t too far from 0. Figure 3.3: Absolute imbalance for a biased-coin scheme with \\(P=0.667\\). Figure 3.4 shows four realisations of the random walk with \\(P=0.55\\). Here, the imbalance is able to get very high (note the change in \\(y\\)-axis); for example in the first plot, if we stopped the trial at \\(n=50\\) we would have 34 participants in one arm and only 16 in the other. Figure 3.4: Absolute imbalance for a biased-coin scheme with \\(P = 0.55\\). By contrast, with \\(P=0.9\\) as in Figure 3.5, there is much less imbalance. However, this brings with it greater predictability. Although allocation is always random, given some degree of imbalance (likely to be known about by those executing the trial), the probability of guessing the next allocation correctly is high (0.9). This invites the biases we have been trying to avoid, albeit in an imperfect form. Figure 3.5: Absolute imbalance for a biased-coin scheme with \\(P = 0.9\\). Efron’s suggestion for implementation was that each clinician would received an unordered stack of envelopes. Each would contain three more envelopes, each with instructions covering one of the three possible cases (\\(\\lvert D\\left(n\\right)\\rvert&lt;0,\\,\\lvert D\\left(n\\right)\\rvert=0\\) and \\(\\lvert D\\left(n\\right)\\rvert&gt;0\\)). The clinician would open the appropriate envelope and implement the instruction. Remember this was 1971! A big disadvantage to the biased coin scheme is that the same probability is used regardless of the size of the imbalance (assuming it isn’t zero). In the next section, we introduce a method where the probability of allocating the next patient to the underrepresented treatment gets larger as the imbalance grows. 3.2.3.2 Urn models Urn models for treatment allocation use urns in the way that you might well remember from school probability (or indeed often we had drawers of socks). They were first applied to clinical trials by Wei (1978). In this setting, the urn starts off with a ball for each treatment, and a ball is added to the urn each time a participant is allocated. The ball is labelled according to the treatment allocation that participant did not receive. To allocate the next participant, a ball is drawn from the urn. If the allocations at this point are balanced, then the participant has equal probability of being allocated to each treatment. If there is imbalance, there will be more balls labelled by the underrepresented treatment, and so the participant is more likely to be allocated to that one. The greater the imbalance, the higher the probability of reducing it. The process described so far is a \\(UD\\left(1,1\\right)\\); there is one ball for each treatment to start with, and one ball is added to the urn after each allocation. To be more general, we can assume a \\(UD\\left(r,s\\right)\\) scheme. Now, there are \\(r\\) balls for each treatment in the urn to begin with, and \\(s\\) are added after each allocation. Near the start of the allocation, the probabilities are likely to change a lot to address imbalance, but once a ‘reasonable number’ of allocations have been made it is likely to settle into simple random sampling (or very close). Once again, we can find the transition probabilities by considering the absolute imbalance \\(\\lvert D\\left(n\\right) \\rvert\\). Suppose that after participant \\(n\\), \\(N_T\\left(n\\right)\\) participants have been allocated to group \\(T\\), and \\(N_C\\left(n\\right) = n - N_T\\left(n\\right)\\) to group \\(C\\). The imbalance is therefore \\[D\\left(n\\right) = N_T\\left(n\\right) - N_C\\left(n\\right) = 2N_T\\left(n\\right) - n.\\] After \\(n\\) allocations there will be \\(2r + ns\\) balls in the urn: \\(r\\) for each treatment at the start, and \\(s\\) added after each allocation. Of these, \\(r + N_C\\left(n\\right)s\\) will be labelled by treatment \\(T\\) and \\(r + N_T\\left(n\\right)s\\) by treatment \\(C\\). To think about the probabilities for the absolute imbalance \\(\\lvert D\\left(n\\right)\\rvert\\), we have to be careful now about which direction it is in. If the trial currently (after allocation \\(n\\)) has an imbalance of participants in favour of treatment \\(C\\), then the probability that it becomes less imbalanced at the next allocation is the probability of the next allocation being to treatment \\(T\\), which is \\[ \\begin{aligned} p\\left(\\lvert D\\left(n+1\\right)\\rvert = j-1 \\mid D\\left(n\\right)=j, j&gt;0\\right) &amp; = \\frac{r + N_C\\left(n\\right)s}{2r + ns} \\\\ &amp; = \\frac{r + \\frac{1}{2}\\left(n + D\\left(n\\right)\\right)s}{2r + ns} \\\\ &amp; = \\frac{1}{2} + \\frac{D\\left(n\\right)s}{2\\left(2r + ns\\right)} \\\\ &amp; = \\frac{1}{2} + \\frac{\\lvert D\\left(n\\right)\\rvert s}{2\\left(2r + ns\\right)}. \\end{aligned} \\] Similarly, if there is currently an excess of patients allocated to treatment \\(T\\), then the imbalance will be reduced if the next allocation is to treatment \\(C\\), and so the conditional probability is \\[ \\begin{aligned} p\\left(\\lvert D\\left(n+1\\right)\\rvert = j-1 \\mid D\\left(n\\right)=j, j&lt;0\\right) &amp; = \\frac{r + N_T\\left(n\\right)s}{2r + ns} \\\\ &amp; = \\frac{r + \\frac{1}{2}\\left(n - D\\left(n\\right)\\right)s}{2r + ns} \\\\ &amp; = \\frac{1}{2} - \\frac{D\\left(n\\right)s}{2\\left(2r + ns\\right)}\\\\ &amp; = \\frac{1}{2} + \\frac{\\lvert D\\left(n\\right)\\rvert s}{2\\left(2r + ns\\right)}. \\end{aligned} \\] Because the process is symmetrical, an imbalance of a given magnitude (say \\(\\lvert D\\left(n\\right)\\rvert=j\\)) is equally likely to be in either direction. That is \\[p\\big(D\\left(n\\right) &lt; 0 \\mid \\lvert D\\left(n\\right)\\rvert =j \\big)= p\\big(D\\left(n\\right) &gt; 0 \\mid \\lvert D\\left(n\\right)\\rvert =j \\big) = \\frac{1}{2}.\\] Therefore we can use the law of total probability (or partition theorem) to find that \\[ p\\big(\\lvert D\\left(n+1\\right) \\rvert = j-1 \\mid \\lvert D\\left(n\\right) \\rvert = j \\big) = \\frac{1}{2} + \\frac{\\lvert D\\left(n\\right)\\rvert s}{2\\left(2r + ns\\right)}. \\] Since the two probabilities are equal this is trivial. Since the only other possibility is that the imbalance is increased by one, we also have \\[p\\big(\\lvert D\\left(n+1\\right) \\rvert = j+1 \\mid \\lvert D\\left(n\\right) \\rvert = j \\big) = \\frac{1}{2} - \\frac{\\lvert D\\left(n\\right)\\rvert s}{2\\left(2r + ns\\right)}. \\] As with the biased coin design, we also have the possibility that the imbalance after \\(n\\) allocations is zero, in which case the absolute imbalance after the next allocation will definitely be one. This gives us another simple random walk, with \\[ \\begin{aligned} P\\big(\\lvert D\\left(n+1\\right) \\rvert = 1 \\mid \\lvert D\\left(n\\right)=0\\big)&amp; = 1\\\\ P\\big(\\lvert D\\left(n+1\\right) \\rvert = j+ 1 \\mid \\lvert D\\left(n\\right)=j\\big)&amp; = \\frac{1}{2} - \\frac{\\lvert D\\left(n\\right)\\rvert s}{2\\left(2r + ns\\right)}\\\\ P\\big(\\lvert D\\left(n+1\\right) \\rvert = j-1 \\mid \\lvert D\\left(n\\right)=j\\big)&amp; = \\frac{1}{2} + \\frac{\\lvert D\\left(n\\right)\\rvert s}{2\\left(2r + ns\\right)} \\end{aligned} \\] Figure 3.6: Four realisations of absolute imbalance for r=1, s=1, N=50. Figure 3.7: Four realisations of absolute imbalance for r=1, s=8, N=50. Figure 3.8: Four realisations of absolute imbalance for r=8, s=1, N=50. We see that imbalance is reduced, particularly for small \\(n\\). A small \\(r\\) and large \\(s\\) enhance this, since the large number (\\(s\\)) of balls added to the urn with each allocation weight the probabilities more heavily, as in Figure 3.7. By contrast, if \\(r\\) is large and \\(s\\) is small, as in Figure 3.8, the probabilities stay closer to \\(\\left(\\frac{1}{2}, \\frac{1}{2}\\right)\\) and so more imbalance occurs early on. 3.3 Incorporating baseline measurements At the start of the trial (ideally before allocation) various baseline measurements are usually taken. If the primary outcome variable is a continuous measurement (eg. blood pressure, weight,…) this same quantity will often be included, so that there is some measure of each participant’s condition/symptoms at the start of the trial. Factors such as age, sex, level of symptoms, things to do with treatment history and many others are included. Essentially, we include any variable we can that may lead to bias if not properly dealt with. The crucial thing is that none of these measurements (taken when they are) should be affected by the trial. Such baseline measurements can be used in allocation. 3.3.1 Stratified sampling The usual method of achieving balance with respect to prognostic factors is to divide each factor into several levels and to consider treatment assignment separately for patients having each particular combination of such factor levels. Such groups of patients are commonly referred to as randomization groups or strata. Treatment assignment is performed entirely separately for each stratum, a permuted block design of the type mentioned above often being used. In fact, using purely random treatment assignment for each stratum is equivalent to simple random assignment, so that some equalization of treatment numbers within each stratum is essential. Both the biased coin design and the urn design were intended for use in this way, adjusting in relation to imbalance within each stratum independently. This whole procedure is analogous to performing a factorial experiment, without being able to control the factor levels of the experimental units. Example 3.5 Suppose we are planning a trial involving people over the age of 50, and we anticipate that age and sex might both play an important role in how participants respond to the treatment. For sex, we use the levels ‘male’ and ‘female’, and for age we split the range into 50-65, 66-80 and 81 or over. We therefore have six strata, and we use an allocation strategy independently in each stratum. For example, below we have used randomly permuted blocks of length four. Male Female 50-65 ABAB BBAA … ABBA BBAA … 66-80 BAAB AABB … BABA BAAB … 81 and over ABAB ABBA … ABBA BAAB … Each time a new participant arrives, we follow the randomization pattern for their stratum. We could use another allocation scheme within each stratum, for example an urn model or a biased coin. It is important that we use one that aims to conserve balance, or else the benefits of stratification are lost. A difficulty with stratified sampling is that the number of strata can quickly become large as the number of factors (or the number of levels within some factors) increases. For example, if we have four prognostic factors each with three levels, there are \\(3^4=81\\) strata. This creates a situation that is at best unwieldy, and at worst completely unworkable; in a small trial (with say 100 patients in each arm) there may be some strata with no patients in (this is actually not a problem), and probably many more with only one (this is much more problematic). 3.3.2 Minimization Minimization was first proposed by Taves (1974), then shortly after by Pocock and Simon (1975) and Freedman and White (1976). The aim of minimization is to minimize the difference between the two groups. It was developed for use with strata, as an alternative to randomly permuted blocks. Although the method was developed in the seventies, it has only gained popularity relatively recently, mainly as computers have become widely available. To form the strata, the people running the trial must first specify all of the factors they would like to be balanced between the two groups. These should be any variables that are thought to possibly affect the outcome. Example 3.6 The study by Kallis et al. (1994) compares the effect of giving aspirin to patients before coronary artery surgery with giving them a placebo. Interestingly, the effects of aspirin were found to be both positive (decreases platelet aggregation to arachidonic acid and to collagen) and negative (increased likelihood of post-operative excessive blood loss). For their prognostic factors, Kallis et al. (1994) chose age (\\(\\leq{50}\\) or \\(&gt;50\\)), sex (M or F), operating surgeon (3 possibilities) and number of coronary arteries affected (1 or 2). This creates 24 strata. The trial had 100 participants, meaning an average of 4.17 in each stratum. When a patient enters the trial, their level of each factor is listed. The patient is then allocated in such a way as to minimise any difference in these factors between the two groups. The minimization method has evolved since its conception, and exists in several forms. Two areas in which methods vary are Whether continuous variables have to be binned Whether there is any randomness It is generally agreed that if the risk of selection bias cannot be avoided, there should be an element of randomness. It is also usually accepted that if a variable is included in the minimization, it should also be included in the statistical analysis. 3.3.2.1 Minimization algorithm Suppose we have a trial in which patients are recruited sequentially and need to be allocated to a trial arm (of which there are two). Pocock and Simon (1975) give an algorithm in the general case of \\(N\\) treatment arms, but we will not do that here. Suppose there are several prognostic factors over which we require balance, and that these factors have \\(I, J, K, ...\\) levels. In our example above, there would be \\(I=2,\\; J=2,\\; K=3,\\; L=2\\). Note that this equates to 24 strata. At some point in the trial, suppose we have recruited \\(n_{ijkl}\\) patients with levels \\(i,\\,j,\\,k,\\,l\\) of the factors. For example, this may be males, aged over 50, assigned to the second surgeon, with both coronary arteries affected. Within these, \\(n^A_{ijkl}\\) have been assigned to treatment arm \\(A\\), and \\(n^B_{ijkl}\\) to arm \\(B\\). So we have \\[ n^A_{ijkl} + n^B_{ijkl} = n_{ijkl} .\\] If we were to use random permuted blocks within each stratum, then we would be assured that \\[\\lvert n^A_{ijkl} - n^B_{ijkl} \\rvert \\leq{\\frac{1}{2}b},\\] where \\(b\\) is the block length. However, there are two issues with this: There may be very few patients in some strata, in which case RPBs will fail to provide adequate balance. It is unlikely that we actually need this level of balance. The first point is a pragmatic one - the method usually guaranteed to achieve good balance is likely to fail, at least for some strata. The second is more theoretical. In general, we require that groups be balanced according to each individual prognostic factor, but not to interactions. For example, it is often believed that younger patients would have generally better outcomes, but that other factors do not systematically affect this difference. Therefore, it is enough to make sure that the following are all small: \\[ \\begin{aligned} \\lvert n^A_{i+++} - n^B_{i+++} \\rvert&amp;\\text{ for each }i=1,\\ldots,I\\\\ \\lvert n^A_{+j++} - n^B_{+j++} \\rvert&amp;\\text{ for each }j=1,\\ldots,J\\\\ \\ldots&amp; \\end{aligned} \\] where \\(+\\) represents summation over the other factors, so that for example \\[n^A_{++k+} = \\sum\\limits_{i,j,l}{n^A_{ijkl}}\\] is the total number of patients with level \\(k\\) of that factor assigned to treatment arm \\(A\\). Therefore, instead of having \\(IJKL\\) constraints constraints, as we would with using randomly permuted blocks (or some other randomization method) within each stratum, we have \\(I+J+K+L\\) constraints, one for each level of each factor. In our example this is 9 constraints rather than 24. In order to implement minimisation, we follow these steps: Allocate the first patient by simple randomisation. Suppose that at some point in the trial we have recruited \\(n_{ijkl}\\) patients with prognostic factors \\(i,\\,j,\\,k,\\,l\\). Of these \\(n^A_{ijkl}\\) are allocated to treatment arm \\(A\\) and \\(n^B_{ijkl}\\) to arm \\(B\\). A new patient enters the trial. They have prognostic factors at levels \\(w,\\,x,\\,y,\\,z\\). We form the sum \\[\\begin{equation} \\left(n^A_{w+++} - n^B_{w+++}\\right) + \\left(n^A_{+x++} - n^B_{+x++}\\right) + \\left(n^A_{++y+} - n^B_{++y+}\\right) + \\left(n^A_{+++z} - n^B_{+++z}\\right). \\tag{3.1} \\end{equation}\\] If the sum from step 4 is negative (that is, allocation to arm \\(B\\) has dominated up to now) then we allocate the new patient to arm \\(A\\) with probability \\(P\\), with \\(P&gt;0.5\\). If the sum is positive, they are allocated to arm \\(B\\) with probability \\(P\\). If the sum is zero, they are allocated to arm \\(A\\) with probability \\(\\frac{1}{2}\\). Some people set \\(P=1\\), whereas others would set \\(\\frac{1}{2}&lt;P&lt;1\\) to retain some randomness. Although setting \\(P=1\\) makes the system deterministic, to predict the next allocation a doctor (or whoever) would need to know \\(n^A_{i+++}\\) and so on. This is very unlikely unless they are deliberately seeking to disrupt the trial. However, generally the accepted approach is becoming to set \\(P&lt;1\\). Example 3.7 From Altman (1990) (citing Fentiman, Rubens, and Hayward (1983)). In this trial, 46 patients with breast cancer were allocated to receive either Mustine (arm A) or Talc (arm B) as treatment for pleural effusions (fluid between the walls of the lung). They used four prognostic factors: age (\\(\\leq{50}\\) or \\(&gt;50\\)), stage of disease (I or II, III or IV), time in months between diagnosis of breast cancer and diagnosis of pleural effusions (\\(\\leq{30}\\) or \\(&gt;30\\)) and menopausal status (Pre or post). Let’s suppose that 15 patients have already been allocated. The totals of patients in each treatment arm in terms of each level of each prognostic factor are shown in the table below. factor level Mustine (A) Talc (B) Age 1. 50 or younger 3 4 Age 2. &gt;50 4 4 Stage 1. I or II 1 2 Stage 2. III or IV 6 6 Time interval 1. 30 months or less 4 2 Time interval 2. &gt;30 months 4 5 Menopausal status 1. Pre 4 3 Menopausal status 2. Post 5 3 Suppose our sixteenth patient is under 50, has disease at stage III, has less than 30 months between diagnoses and is pre-menopausal. Our calculation from step 4 of the minimisation algorithm is therefore \\[ \\begin{aligned} \\left(n^A_{1+++} - n^B_{1+++}\\right) + \\left(n^A_{+2++} - n^B_{+2++}\\right) + \\left(n^A_{++1+} \\right.&amp; \\left.- n^B_{++1+}\\right) + \\left(n^A_{+++1} - n^B_{+++1}\\right) \\\\ &amp; = \\left(3-4\\right) + \\left(6-6\\right) + \\left(4-2\\right) + \\left(4-3\\right) \\\\ &amp; = -1 + 0 + 2 + 1\\\\ &amp; = 2 . \\end{aligned} \\] Since our sum is greater than zero, we allocate the new patient to arm B (talc) with some probability \\(P\\in\\left(0.5,1\\right)\\) and update the table before allocating patient 17. One shortcoming of minimisation is that the factors are equally weighted in the algorithm, regardless of the number of patients with that particular factor level. For example, suppose at some later stage of allocation in our Mustine example, only four patients with stage I or II disease had been recruited, and that one of these had been allocated to group \\(A\\) and three to group \\(B\\). At the same point, 18 of the recruited number were post-menopausal, and of these 10 had been allocated to group \\(A\\) and 8 to group \\(B\\). The values contributed to the sum in Equation (3.1) are \\(+2\\) and \\(-2\\), so these imbalances effectively cancel one another out, but intuitively it would feel sensible to prioritise equal distribution within the stage I or II women, since proportionally this stratum is less balanced. Wei (1978) proposed an extension of the Urn Design that does exactly this, but we won’t cover this method in our course. 3.4 Problems around allocation In clinical trials papers, the allocation groups are usually summarised in tables giving summary statistics (eg. mean and SD) of each characteristic for the control group and the intervention group. The aim of these is to show that the groups are similar enough for any difference in outcome to be attributed to the intervention itself. Figure 3.9 shows an example, taken from Ruetzler et al. (2013). Figure 3.9: Summary statistics for an RCT comparing a licorice gargle (the intervention) to a sugar-water gargle (the standard). From Ruetzler et al. (2013) The problem here is that only the marginal distributions are compared for similarity. Consider the following (somewhat extreme and minimalistic) scenario. A study aims to investigate the effect of some treatment, and to balance for gender and age in their allocation, resulting in the following summary table. Male Female Control 57.51 (7.09) 40.31 (5.83) Intervention 44.19 (5.96) 60.03 (5.27) This appears to be a reasonably balanced design. However, if we look at the joint distribution, we see that there are problems. If the intervention is particularly effective in older men, our trial will not notice. Likewise, if older women generally have a more positive outcome than older men, our trial may erroneously find the intervention to be effective. Although this example is highly manufactured and [hopefully!] unlikely to take place in real life, for clinical trials there are often many demographic variables and prognostic factors being taken into account. Achieving joint balance across all them is very difficult, and extremely unlikely to happen if it isn’t aimed for. Treasure and MacRae (1998) give an example in relation to a hypothetical study on heart disease Supposing one group has more elderly women with diabetes and symptoms of heart failure. It would then be impossible to attribute a better outcome in the other group to the beneficial effects of treatment since poor left ventricular function and age at outset are major determinants of survival in any longitudinal study of heart disease, and women with diabetes, as a group, are likely to do worse. At this point the primary objective of randomisation—exclusion of confounding factors—has failed. … If a very big trial fails, because, for example, the play of chance put more hypertensive smokers in one group than the other, the tragedy for the trialists, and all involved, is even greater. However, this issue is rarely addressed in clinical trials: a lot of faith is placed (with reasonable justification) in the likely balance achieved by random sampling, whatever method is used. We will also see in the next Chapter that we can account for some degree of imbalance at the analysis stage. References Altman, Douglas G. 1990. Practical Statistics for Medical Research. CRC press. Altman, Douglas G, and J Martin Bland. 1999. “Treatment Allocation in Controlled Trials: Why Randomise?” Bmj 318 (7192): 1209–9. Cottingham, Marci D, and Jill A Fisher. 2022. “Gendered Logics of Biomedical Research: Women in US Phase i Clinical Trials.” Social Problems 69 (2): 492–509. Efron, Bradley. 1971. “Forcing a Sequential Experiment to Be Balanced.” Biometrika 58 (3): 403–17. Fentiman, Ian S, Robert D Rubens, and John L Hayward. 1983. “Control of Pleural Effusions in Patients with Breast Cancer a Randomized Trial.” Cancer 52 (4): 737–39. Freedman, LS, and Susan J White. 1976. “On the Use of Pocock and Simon’s Method for Balancing Treatment Numbers over Prognostic Factors in the Controlled Clinical Trial.” Biometrics, 691–94. Goldacre, B. 2012. Bad Pharma: How Medicine Is Broken, and How We Can Fix It. HarperCollins Publishers. https://books.google.co.uk/books?id=4amY1Q6Id4QC. Health, National Institute of. 2023. “History of Women’s Participation in Clinical Research.” Office of Research on Women’s Health. https://orwh. od. nih. gov/toolkit …. https://orwh.od.nih.gov/toolkit/recruitment/history. Kallis, P, JA Tooze, S Talbot, D Cowans, DH Bevan, and T Treasure. 1994. “Pre-Operative Aspirin Decreases Platelet Aggregation and Increases Post-Operative Blood Loss–a Prospective, Randomised, Placebo Controlled, Double-Blind Clinical Trial in 100 Patients with Chronic Stable Angina.” European Journal of Cardio-Thoracic Surgery: Official Journal of the European Association for Cardio-Thoracic Surgery 8 (8): 404–9. Kar, Sumit, Ajay Krishnan, Preetha K, and Atul Mohankar. 2012. “A Review of Antihistamines Used During Pregnancy.” Journal of Pharmacology and Pharmacotherapeutics 3 (2): 105–8. Pocock, Stuart J, and Richard Simon. 1975. “Sequential Treatment Assignment with Balancing for Prognostic Factors in the Controlled Clinical Trial.” Biometrics, 103–15. Ruetzler, Kurt, Michael Fleck, Sabine Nabecker, Kristina Pinter, Gordian Landskron, Andrea Lassnigg, Jing You, and Daniel I Sessler. 2013. “A Randomized, Double-Blind Comparison of Licorice Versus Sugar-Water Gargle for Prevention of Postoperative Sore Throat and Postextubation Coughing.” Anesthesia &amp; Analgesia 117 (3): 614–21. Taves, Donald R. 1974. “Minimization: A New Method of Assigning Patients to Treatment and Control Groups.” Clinical Pharmacology &amp; Therapeutics 15 (5): 443–53. Treasure, Tom, and Kenneth D MacRae. 1998. “Minimisation: The Platinum Standard for Trials?: Randomisation Doesn’t Guarantee Similarity of Groups; Minimisation Does.” Bmj. British Medical Journal Publishing Group. Vitale, Cristiana, Massimo Fini, Ilaria Spoletini, Mitja Lainscak, Petar Seferovic, and Giuseppe MC Rosano. 2017. “Under-Representation of Elderly and Women in Clinical Trials.” International Journal of Cardiology 232: 216–21. Wei, LJ. 1978. “An Application of an Urn Model to the Design of Sequential Controlled Clinical Trials.” Journal of the American Statistical Association 73 (363): 559–63. "],["computer-practical-1---missing-data.html", "A Computer Practical 1 - Missing data A.1 Missing data A.2 Understanding the patterns of missingness A.3 Exploring the relationship between missingness and other variables A.4 What to do about missing data?!", " A Computer Practical 1 - Missing data In this computer practical we focus on an important issue in clinical trials (and most real world projects!): missing data. There will be a bit more reading than in future practicals, to give you the necessary theory and background. We will only have time to skim the surface of working with missing data, but if you want to find out more, some good references are Little and Rubin (2019) and chapter 17 of Gelman, Hill, and Vehtari (2021). Consider it a sort of informal formative assignment to finish this practical in your own time if you don’t in class. Or, at the very least, you might need to return to it while working on future assignments. For this reason, it would be sensible to keep track of everything you do in an .R file that you can return to in the future. There will be a mixture of full solutions, examples of possible solutions and example code to adapt. If you’re not sure how to do something, please ask! R practicalities There are many, many packages in R that implement methods for designing and analysing clinical trials (see a list at CRAN task view). We will look at some of these, and will also write our own code for some tasks. Remember that to install a package, you can do install.packages(&quot;&lt;packagename&gt;&quot;) and to then load the package (it doesn’t load automatically on install) enter library(&lt;packagename&gt;) If you have problems running R on your laptop, or on the university machines, the most foolproof way might be to use Github codespaces (thanks to Louis Aslett, who developed this for Data Science and Statistical Computing II). You may be familiar with this approach if you did Bayesian Computational Modelling III. An advantage of this is that you can open the same codespace (the same instance of R) from any computer, so if you plan to work on things (for example your summative assignment, which will involve some R) from more than one computer, this might be ideal. Codespace requires you to have a github account (you can sign up for free here) and there is a short guide to creating a github account here. Direct link to codespace Instructions for how to use codespace A.1 Missing data In [almost] any real-world study or trial, there will be some missing data. This can happen for a whole host of reasons: perhaps some participants dropped out completely, or couldn’t make some appointments. Perhaps some data were lost or corrupted. Perhaps some participants decided not to provide certain details, or didn’t comply properly with the study. Why does this matter? Or, why do we need to think properly about this? Well, a huge amount of work in the planning and design of an RCT goes into the random allocation: we want to eliminate all sources of bias (including those we can’t observe, or aren’t even aware of) by randomly balancing the participants between the trial arms. If some of these participants’ data are missing, we can no longer be confident that we still have this balance. Dealing with missing data boils down to two main tasks: Understanding the pattern(s) of missingness Processing the data to mitigate against the effect of the missingness so this is what we’ll be working on now. Before that though, we need some data to work with! A.1.1 Datasets The datasets we’ll work with come from the packages medicaldata and smdi, so you’ll need to install those if you don’t have them. We’ll also be using the packages naniar and visdat, which contain lots of methods for handling missing data, and rstanarm, which will enable us to easily sample from regression models. Other packages are available, as you can see from the CRAN task view on Missing Data. We’ll also use tidyverse for various plotting and data handling tasks. require(medicaldata) library(naniar) library(smdi) library(tidyverse) library(visdat) library(rstanarm) Throughout this practical we’ll work with three datasets. A.1.1.1 Supraclavicular The first dataset is the supraclavicular data. This is a fairly simple data set (at least in terms of missingness) which I’ll use to to demonstrate techniques before asking you to work on the more complex data! Exercise A.1 Load the supraclavicular data. - What is the study about? - What is the primary outcome? - What are the baseline covariates (remember these must be measured before allocation) Create a data frame containing just the baseline covariates, the allocation and the primary outcome variable. Make sure these are of the correct type. Click for solution Solution. The details of the study can be found using ?supraclavicular. The primary outcome variable is time to 4-nerve sensory block, which has the column name onset_sensory. The baseline covariates are gender, BMI and age. To create our data frame, we need sup_df = supraclavicular[ ,c(2:5, 9)] sup_df = sup_df%&gt;% mutate(across(c(group, gender), factor)) A.1.1.2 Lung cancer dataset This is the smdi_data dataset from the package smdi. The intervention group variable is exposure. The outcome data are survival (or ‘time-to-event’) data: in this study, the ‘event’ is death and the follow-up period is five (probably years, but it doesn’t say!). Some participants are still alive at the end of the follow-up period (so they have status=0) and the data are therefore right censored. We will learn more about this type of data later in the course. For now, the only preparation to do is to convert status to a factor variable: smdi_data$status = factor(smdi_data$status) This is a synthetic (or possibly synthetically altered) dataset designed for use with missing data exploration, so we have the advantage that the help file tells about the missingness mechanisms (more on that soon). A.1.1.3 Obstetrics and Periodontal Therapy The final dataset we’ll work with is opt, which is about the treatment of maternal periodontal disease and its effect on birthweight and term. Exercise A.2 Use ?opt to find out about this trial. There are a lot of columns here, but we won’t keep all of them. Our dataset (for now) will be opt_df = opt[ ,c(1:4, 10:22, 72)] which retains most of the baseline covariates, intervention group and outcome variable (birthweight). There is some ‘messiness’ in the data, for example for some variables missing values are recorded as \"\", rather than NA. We’ll sort that now by running the following command opt_df = opt_df %&gt;% mutate(across(c(Use.Tob, Use.Alc, Drug.Add), gsub, pattern = &quot;^ +$&quot;, replacement = NA))%&gt;% mutate(across(c(Use.Tob, Use.Alc, Drug.Add), factor)) A.2 Understanding the patterns of missingness The first thing we’ll do is explore the data to find out what the pattern of missingness is. First of all, we can visualise which data are missing. A.2.1 Visualising missingness The function vis_dat (from visdat) gives an excellent first look at a dataset, colouring data by type (and missing data in grey). The default is to sort the columns by type, but you can see below that I’ve made it keep to the origianl order. vis_dat(sup_df, sort_type=F) The functions gg_miss_var, gg_miss_case and gg_miss_upset (all from naniar) allow us to quickly see how much missing data there is, either by variable, by case or by intersection. Look at the help files to find out what the arguments do. We see that in supraclavicular there are three missing entries for BMI, and all other variables are complete. gg_miss_var(sup_df) Plotting by cases shows that each of these missing data are associated with a different participant, so there are three participants with one missing item each. gg_miss_case(sup_df) md.pattern(sup_df) ## group gender age onset_sensory bmi ## 100 1 1 1 1 1 0 ## 3 1 1 1 1 0 1 ## 0 0 0 0 3 3 Exercise A.3 Make these plots for the remaining datasets, smdi_data and opt_df. How does the missingness compare? Which plots do you find more useful and why? Click for solution Solution. Lung cancer We see there is missingness for three variables: vis_dat(smdi_data) The naniar functions can show us how this is spread across the variables and participants. gg_miss_var(smdi_data, show_pct=T) gg_miss_case(smdi_data, order_cases = T) The function md.pattern shows us how many participants have each combination of missing data: md.pattern(smdi_data, rotate.names = T) ## exposure age_num female_cat smoking_cat physical_cat alk_cat histology_cat ses_cat ## 795 1 1 1 1 1 1 1 1 ## 479 1 1 1 1 1 1 1 1 ## 446 1 1 1 1 1 1 1 1 ## 263 1 1 1 1 1 1 1 1 ## 151 1 1 1 1 1 1 1 1 ## 176 1 1 1 1 1 1 1 1 ## 93 1 1 1 1 1 1 1 1 ## 97 1 1 1 1 1 1 1 1 ## 0 0 0 0 0 0 0 0 ## copd_cat eventtime status pdl1_num ecog_cat egfr_cat ## 795 1 1 1 1 1 1 0 ## 479 1 1 1 1 1 0 1 ## 446 1 1 1 1 0 1 1 ## 263 1 1 1 1 0 0 2 ## 151 1 1 1 0 1 1 1 ## 176 1 1 1 0 1 0 2 ## 93 1 1 1 0 0 1 2 ## 97 1 1 1 0 0 0 3 ## 0 0 0 517 899 1015 2431 Obstetrics and Periodontal Therapy Using vis_dat we see that there is a lot of missing data in the opt dataset, and that some variables are particularly badly affected. vis_dat(opt_df) Now the naniar functions really do help us to understand what we’re dealing with! gg_miss_var(opt_df, show_pct=T) gg_miss_case(opt_df, order_cases = T, show_pct=T) Not many individual participants have more than about 25% of their data missing, but there are some variables that are missing for nearly all participants (more on this later). A.2.2 Summary tables We may also want to visualise or summarise missingness in a table, and there are various ways to do this, for example miss_case_summary, miss_var_summary and miss_var_summary. Exercise A.4 Use the three table generating functions listed above on our datasets. Do they give you any new information compared to the plots? Click for solution Solution. Working through the list of functions (just for opt_df), we have: miss_case_summary(opt_df) ## # A tibble: 823 × 3 ## case n_miss pct_miss ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 423 9 50 ## 2 80 8 44.4 ## 3 93 8 44.4 ## 4 477 8 44.4 ## 5 539 8 44.4 ## 6 11 7 38.9 ## 7 21 7 38.9 ## 8 43 7 38.9 ## 9 54 7 38.9 ## 10 150 7 38.9 ## # ℹ 813 more rows This shows how many variables (both in number and as a percentage of the total number of variables) are missing, for each case (in decreasing order of missingness). miss_case_table(opt_df) ## # A tibble: 9 × 3 ## n_miss_in_case n_cases pct_cases ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 7 0.851 ## 2 2 87 10.6 ## 3 3 462 56.1 ## 4 4 224 27.2 ## 5 5 17 2.07 ## 6 6 12 1.46 ## 7 7 9 1.09 ## 8 8 4 0.486 ## 9 9 1 0.122 miss_case_table tabulates the number of cases with \\(n\\) missing variables, for \\(n=1,\\ldots\\). The remaining functions look at things from the point of view of variables: miss_var_summary(opt_df) ## # A tibble: 18 × 3 ## variable n_miss pct_miss ## &lt;chr&gt; &lt;int&gt; &lt;num&gt; ## 1 BL.Drks.Day 810 98.4 ## 2 BL.Diab.Type 799 97.1 ## 3 BL.Cig.Day 731 88.8 ## 4 N.prev.preg 217 26.4 ## 5 BMI 73 8.87 ## 6 Use.Alc 27 3.28 ## 7 Drug.Add 27 3.28 ## 8 Use.Tob 26 3.16 ## 9 Birthweight 14 1.70 ## 10 PID 0 0 ## 11 Clinic 0 0 ## 12 Group 0 0 ## 13 Age 0 0 ## 14 Education 0 0 ## 15 Public.Asstce 0 0 ## 16 Hypertension 0 0 ## 17 Diabetes 0 0 ## 18 Prev.preg 0 0 Now we see how many (and what percentage) of cases are missing for each variable. There are many, many possible ways to visualise or tabulate missing data, and we have used but a few. If you want to find more, you can look in the help file for naniar, or indeed at another package designed for working with missing data. A.2.3 Mechanisms of missingness So far, things have been a bit ad-hoc. We may have noticed some patterns or trends, but we haven’t subjected these to any scrutiny, or used any statistical methodology to understand the missingness. When working with missing data, it’s important to think about the mechanism that is causing some data to be missing. Is there some systematic reason why some variables are missing? Broadly speaking, there are three types of missing data. These were first coined by Rubin (1976). A.2.3.1 Missing completely at random (MCAR) If data are MCAR, then the probability of missingness is the same for all units: missingness is statistically independent of all covariates (observed and unobserved), of the treatment and of the outcome. If each participant decided whether or not to provide a certain piece of information by rolling a dice (eg. 1 = don’t provide), then the resulting missingness would be MCAR. This type of missingness is the simplest to deal with, because removing the missing units is unlikely to cause any bias. However, it’s extremely rare in real life, and it’s difficult to even think of an example where it would definitely hold! A.2.3.2 Missing at random (MAR) For data to be MAR, the probability of missingness must depend only on available information. In this case, we can use the available information to model the missingness. MAR data are somewhat more common (or at least the mechanism is more commonly assumed than MCAR), and is thankfully still moderately simple to deal with. If missingness is ‘at random’, then adjusting for the relevant covariates in the analysis will avoid bias. A.2.3.3 Missing not at random (MNAR) This is the trickiest (and probably most common) mechanism, in which the missingness depends on unobserved data. It is likely then that the unobserved (and therefore unavailable) information also predicts the value that is missing, and possibly also the outcome. For example, suppose that the treatment in a clinical trial causes some unwanted side effect, such as pain. In this case, a participant in the intervention group is more likely to drop out of the study than a participant in the control group. Unless we measure this side effect (for example, a pain score), the resulting missingness is not at random. The most difficult case of MNAR is when the missingness depends on the (potentially missing) variable itself. For example, in a trial of a weight loss intervention, participants with greater weights might be more reticent to reveal them, especially if they feel the trial is going badly. MNAR mechanisms can be [imperfectly] modelled, or else mitigated by including more covariates in the data, which brings the mechanism closer to MAR. It is vital to work with the subject experts, who will have a much better idea of the sorts of mechanisms that might be causing missingness in their study. We can never prove which of these is the case, since by definition we don’t have the information we would need to establish that the mechanism is (or isn’t) MNAR. All we can do is study patterns in the data and find evidence one way or the other. A.3 Exploring the relationship between missingness and other variables In a clinical trial, ultimately what we care about is whether the missingness has changed our understanding of the outcome variable(s). This is most likely to happen if the missingness is related to the outcome variable. This could happen either directly, or because the missingness is correlated to a variable that affects the outcome. Again, we will explore things visually before using some more rigorous methods. Now, instead of simply understanding how much missing data there is, and which variables and/or cases are involved, we want to look at the relationships between missingness and the values of the other variables. In the package naniar you can create a copy of the data frame containing just NA and !NA, indexing exactly where the missing values are. as_shadow(sup_df) group_NA gender_NA bmi_NA age_NA onset_sensory_NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA !NA To avoid duplication of the original names, the column names are suffixed by ’_NA’. This means it can be appended to the original data frame to create what the authors of naniar call a nabular object. nabular(sup_df) group gender bmi age onset_sensory group_NA gender_NA bmi_NA age_NA onset_sensory_NA 1 0 41.15 52 0 !NA !NA !NA !NA !NA 2 0 25.22 54 7 !NA !NA !NA !NA !NA 2 0 34.14 46 24 !NA !NA !NA !NA !NA 1 0 41.57 54 4 !NA !NA !NA !NA !NA 1 1 27.17 41 30 !NA !NA !NA !NA !NA 2 1 22.05 21 4 !NA !NA !NA !NA !NA 1 1 26.32 68 12 !NA !NA !NA !NA !NA 2 1 24.69 61 13 !NA !NA !NA !NA !NA 1 0 35.63 44 27 !NA !NA !NA !NA !NA 1 0 35.12 28 4 !NA !NA !NA !NA !NA 1 0 36.11 36 3 !NA !NA !NA !NA !NA 1 0 28.34 60 21 !NA !NA !NA !NA !NA 2 0 22.60 34 9 !NA !NA !NA !NA !NA 2 1 30.14 64 9 !NA !NA !NA !NA !NA 2 1 26.36 37 5 !NA !NA !NA !NA !NA 2 0 NA 51 50 !NA !NA NA !NA !NA 2 1 22.32 58 7 !NA !NA !NA !NA !NA 1 0 37.84 24 2 !NA !NA !NA !NA !NA 2 1 39.85 28 6 !NA !NA !NA !NA !NA 1 0 31.21 50 3 !NA !NA !NA !NA !NA 2 1 25.64 74 5 !NA !NA !NA !NA !NA 2 1 21.26 52 41 !NA !NA !NA !NA !NA 1 0 24.22 53 4 !NA !NA !NA !NA !NA 2 1 25.10 19 14 !NA !NA !NA !NA !NA 1 0 25.42 41 7 !NA !NA !NA !NA !NA 1 0 23.60 49 2 !NA !NA !NA !NA !NA 2 0 28.20 46 4 !NA !NA !NA !NA !NA 1 1 28.33 57 3 !NA !NA !NA !NA !NA 2 0 30.40 50 17 !NA !NA !NA !NA !NA 1 0 42.38 60 1 !NA !NA !NA !NA !NA 1 0 36.98 52 2 !NA !NA !NA !NA !NA 2 1 30.67 39 1 !NA !NA !NA !NA !NA 1 1 23.43 53 1 !NA !NA !NA !NA !NA 2 1 30.61 64 3 !NA !NA !NA !NA !NA 2 1 23.62 51 20 !NA !NA !NA !NA !NA 1 1 30.17 47 6 !NA !NA !NA !NA !NA 1 0 18.80 66 10 !NA !NA !NA !NA !NA 1 1 24.52 59 33 !NA !NA !NA !NA !NA 2 1 29.60 31 39 !NA !NA !NA !NA !NA 1 1 29.16 64 8 !NA !NA !NA !NA !NA 1 1 25.85 61 48 !NA !NA !NA !NA !NA 2 1 25.84 50 9 !NA !NA !NA !NA !NA 2 1 35.36 32 3 !NA !NA !NA !NA !NA 1 1 28.43 54 22 !NA !NA !NA !NA !NA 2 1 35.25 53 27 !NA !NA !NA !NA !NA 2 0 19.70 57 6 !NA !NA !NA !NA !NA 2 1 27.50 56 37 !NA !NA !NA !NA !NA 2 1 24.40 32 38 !NA !NA !NA !NA !NA 1 1 24.30 23 6 !NA !NA !NA !NA !NA 1 0 37.92 61 5 !NA !NA !NA !NA !NA 1 0 23.76 52 4 !NA !NA !NA !NA !NA 2 1 22.12 18 19 !NA !NA !NA !NA !NA 2 0 32.40 42 15 !NA !NA !NA !NA !NA 2 0 20.49 44 23 !NA !NA !NA !NA !NA 1 1 NA 22 16 !NA !NA NA !NA !NA 2 0 32.50 48 8 !NA !NA !NA !NA !NA 2 0 36.72 52 10 !NA !NA !NA !NA !NA 2 0 39.87 48 19 !NA !NA !NA !NA !NA 1 0 33.00 51 13 !NA !NA !NA !NA !NA 1 1 30.70 54 6 !NA !NA !NA !NA !NA 1 0 27.20 36 9 !NA !NA !NA !NA !NA 1 0 30.60 53 9 !NA !NA !NA !NA !NA 1 0 28.33 66 11 !NA !NA !NA !NA !NA 1 0 34.84 60 50 !NA !NA !NA !NA !NA 1 1 NA 50 6 !NA !NA NA !NA !NA 2 0 29.00 53 7 !NA !NA !NA !NA !NA 2 1 28.59 52 26 !NA !NA !NA !NA !NA 2 0 38.19 36 18 !NA !NA !NA !NA !NA 2 0 36.96 66 9 !NA !NA !NA !NA !NA 1 1 22.55 32 16 !NA !NA !NA !NA !NA 2 1 35.15 57 6 !NA !NA !NA !NA !NA 2 0 37.62 54 19 !NA !NA !NA !NA !NA 1 0 42.93 52 13 !NA !NA !NA !NA !NA 2 1 20.98 31 9 !NA !NA !NA !NA !NA 2 1 27.37 36 8 !NA !NA !NA !NA !NA 1 0 27.02 35 5 !NA !NA !NA !NA !NA 1 0 22.83 51 2 !NA !NA !NA !NA !NA 1 0 28.73 56 5 !NA !NA !NA !NA !NA 2 0 29.49 62 10 !NA !NA !NA !NA !NA 1 0 34.08 32 18 !NA !NA !NA !NA !NA 1 0 25.59 57 15 !NA !NA !NA !NA !NA 1 1 34.17 59 12 !NA !NA !NA !NA !NA 2 1 31.39 62 24 !NA !NA !NA !NA !NA 2 0 21.26 25 50 !NA !NA !NA !NA !NA 1 0 24.20 29 8 !NA !NA !NA !NA !NA 1 1 32.28 65 4 !NA !NA !NA !NA !NA 2 1 30.45 28 8 !NA !NA !NA !NA !NA 1 1 23.34 65 6 !NA !NA !NA !NA !NA 2 0 24.54 46 5 !NA !NA !NA !NA !NA 2 0 23.61 67 10 !NA !NA !NA !NA !NA 2 0 43.46 55 10 !NA !NA !NA !NA !NA 1 0 19.91 59 3 !NA !NA !NA !NA !NA 1 1 24.45 38 20 !NA !NA !NA !NA !NA 1 0 27.78 60 7 !NA !NA !NA !NA !NA 2 0 23.06 41 11 !NA !NA !NA !NA !NA 2 0 32.79 68 14 !NA !NA !NA !NA !NA 1 1 24.96 66 12 !NA !NA !NA !NA !NA 2 0 23.06 41 10 !NA !NA !NA !NA !NA 2 1 24.40 19 10 !NA !NA !NA !NA !NA 1 0 22.24 31 9 !NA !NA !NA !NA !NA 1 0 33.91 40 11 !NA !NA !NA !NA !NA 2 1 31.65 53 22 !NA !NA !NA !NA !NA 1 0 41.54 41 40 !NA !NA !NA !NA !NA This is useful because we can investigate the values of the actual data while conditioning on the missingness. We can summarize the outcome distribution according to whether a variable is missing or observed: sup_nab %&gt;% group_by(bmi_NA) %&gt;% summarise_at(.vars = &quot;onset_sensory&quot;, .funs = c(&quot;mean&quot;, &quot;sd&quot;, &quot;var&quot;, &quot;min&quot;, &quot;max&quot;), na.rm = TRUE) ## # A tibble: 2 × 6 ## bmi_NA mean sd var min max ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 !NA 13 11.4 131. 0 50 ## 2 NA 24 23.1 532 6 50 and visualise the outcome distribution for missing and non-missing values of a covariate: ggplot(sup_nab, aes(x = onset_sensory, fill = bmi_NA)) + geom_histogram() We could also explore whether the missingness is related to the values of the other covariates, for example gender (in this data 0=female, 1=male) ggplot(sup_nab, aes(x = gender, fill = bmi_NA)) + geom_bar() This isn’t a great example because there are only three missing BMI values, but you can probably guess what you’ll be doing next… Exercise A.5 For the lung cancer and obstetric periodontal treatment datasets, investigate whether / how the outcome distribution appears to be affected by the missing values. For the smdi_data dataset, remember that the outcome variable is the combination of eventtime and status. Can you think of a way to visualise the data that combines these pieces of information? For opt, ignore the variables BL.Diab.Type, BL.Cig.Day, BL.Cig.Day and N.prev.preg. You can create a temporary opt data frame to work with opt_tmp = opt_df[ ,-c(9,12,14,17)] There are many, many plots you could make here, but try not to spend too long on this - why not divide up tasks between you and your neighbours? Click for solution Solution. We’ll look here in some detail about the lung cancer dataset (smdi_data) - these aren’t really solutions as such, just some more detail of things you could do. smdi_nab = nabular(smdi_data) First by ecog_cat. Since there is a lot more missing data here, I’ve chosen to compare the distributions side-by-side using facet_wrap. This also allows me to colour by status (although it is sort of obvious from the large peak at eventtime=5 that those people are still alive). Setting scales = \"free_y\" makes it easier to compare the overall shape of the distribution. You may have found a different way to display the data that may be equally (or more!) informative - if so that’s fine! smdi_nab %&gt;% group_by(ecog_cat) %&gt;% summarise_at(.vars = &quot;eventtime&quot;, .funs = c(&quot;mean&quot;, &quot;sd&quot;, &quot;var&quot;, &quot;min&quot;, &quot;max&quot;), na.rm = TRUE) ## # A tibble: 3 × 6 ## ecog_cat mean sd var min max ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 2.21 1.80 3.25 0.0000215 5 ## 2 1 2.07 1.79 3.22 0.000754 5 ## 3 &lt;NA&gt; 2.22 1.86 3.46 0.00248 5 ggplot(smdi_nab, aes(x = eventtime, fill = status)) + geom_histogram() + facet_wrap(~ecog_cat_NA, scales = &quot;free_y&quot;) Next by egfr_cat: smdi_nab %&gt;% group_by(egfr_cat) %&gt;% summarise_at(.vars = &quot;eventtime&quot;, .funs = c(&quot;mean&quot;, &quot;sd&quot;, &quot;var&quot;, &quot;min&quot;, &quot;max&quot;), na.rm = TRUE) ## # A tibble: 3 × 6 ## egfr_cat mean sd var min max ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 1.96 1.79 3.22 0.000754 5 ## 2 1 2.94 1.91 3.66 0.0115 5 ## 3 &lt;NA&gt; 2.15 1.76 3.10 0.0000215 5 ggplot(smdi_nab, aes(x = eventtime, fill = status)) + geom_histogram() + facet_wrap(~egfr_cat_NA, scales = &quot;free_y&quot;) and finally by pdl1_num: smdi_nab %&gt;% group_by(pdl1_num) %&gt;% summarise_at(.vars = &quot;eventtime&quot;, .funs = c(&quot;mean&quot;, &quot;sd&quot;, &quot;var&quot;, &quot;min&quot;, &quot;max&quot;), na.rm = TRUE) ## # A tibble: 1,540 × 6 ## pdl1_num mean sd var min max ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6.14 0.655 NA NA 0.655 0.655 ## 2 12.4 0.463 NA NA 0.463 0.463 ## 3 12.9 0.679 NA NA 0.679 0.679 ## 4 13.6 0.358 NA NA 0.358 0.358 ## 5 15.8 0.290 NA NA 0.290 0.290 ## 6 16.7 1.71 NA NA 1.71 1.71 ## 7 17.4 0.245 NA NA 0.245 0.245 ## 8 17.8 1.52 NA NA 1.52 1.52 ## 9 18.7 4.91 NA NA 4.91 4.91 ## 10 19.0 2.03 NA NA 2.03 2.03 ## # ℹ 1,530 more rows ggplot(smdi_nab, aes(x = eventtime, fill = status))+ geom_histogram() + facet_wrap(~pdl1_num_NA, scales = &quot;free_y&quot;) It appears that pdl1_num values are likely to be MNAR, since the outcome distribution looks different (proportionally more early deaths) for the missing values. We could make many more plots of this type: for example, by plotting the distributions of other variables rather than the outcome. For example, we could look at how the missingness of each variable relates to smoking category: library(gridExtra) ecog_sm = ggplot(smdi_nab, aes(x = smoking_cat, fill = ecog_cat_NA))+ geom_bar() egfr_sm = ggplot(smdi_nab, aes(x = smoking_cat, fill = egfr_cat_NA))+ geom_bar() pdl1_sm = ggplot(smdi_nab, aes(x = smoking_cat, fill = pdl1_num_NA))+ geom_bar() grid.arrange(ecog_sm, egfr_sm, pdl1_sm, nrow=1) So, it looks likely that the missingness of egfr_cat depends on smoking status, but less likely that the missingness of the other two variables does. Looking into all the variables one by one like this would take a very long time, and wouldn’t even allow us to make any (useful) conclusions. Really what we want to know is whether there is a significant difference in the observed data compared to the missing data. A.3.1 Statistical summaries of the effect of missingness According to the framework coined by Rubin (1976), if the data are MAR (missing at random) then the missingness can be explained by (some of) the observed covariates. We would therefore expect the participant characteristics to be different between those with missing values and those without. If the missingness is MCAR (missing completely at random) we would expect no significant difference. Similarly, if the data are MNAR (missing not-at-random) due to some unobserved variable that is independent of all observed variables, we would expect no pattern. In reality this is almost never the case (the confounding variables are usually linked to some observed variables) and so really we are testing against the data being MCAR. A.3.1.1 Hotelling’s multivariate t-test This test examines the differences between those observations with an observation (of some partially observed variable) and those without. The test statistic is derived by assuming both groups are drawn from the same multivariate normal distribution, and so a high value of the test statistic (conversely a low p-value) suggests that there are significant differences between the groups. This test is from a generalisation of Student’s \\(t\\)-test made by Hotelling et al. (1931). To perform Hotelling’s multivariate \\(t\\)-test on the sup_df data we enter smdi_hotelling(sup_df) ## covariate hotteling_p ## 1 bmi 0.340 For this data, we find that there is insufficient evidence to reject the hypothesis that the BMI data are MCAR. Exercise A.6 Perform Hotelling’s multivariate \\(t\\)-test on the other two datasets, opt_tmp and smdi_data. What do you find? Click for solution First we’ll look at smdi_data. smdi_hotelling(smdi_data) ## covariate hotteling_p ## 1 ecog_cat 0.783 ## 2 egfr_cat &lt;.001 ## 3 pdl1_num &lt;.001 It appears that ecog_cat may be MCAR, but for egfr_cat and pdl1_num there is sufficient evidence to suggest MAR or MNAR. Now for opt_tmp smdi_hotelling(opt_tmp) ## covariate hotteling_p ## 1 BMI &lt;.001 ## 2 Use.Tob &lt;.001 ## 3 Use.Alc &lt;.001 ## 4 Drug.Add &lt;.001 ## 5 Birthweight &lt;.001 These all appear to have a significant departure from MCAR. Caution: The power of this test (and others like it) can be strongly influenced by sample size, so it is sensible to combine it with a more detailed approach. A.3.1.2 Absolute standardised mean difference The absolute standardised mean difference (ASMD) gives a measure of how different the values of the observed covariates are for missing versus observed values of each partially observed covariate. For every partially observed covariate, there is an ASMD for each other covariate. Label the partially observed covariate \\(X_M\\), and suppose \\(X_1,\\ldots,X_K\\) are the other covariates. The dataset is split into those cases with \\(X_M\\) observed and those with \\(X_M\\) missing. For each covariate \\(X_1,\\ldots,X_K\\) we find the absolute value of the difference in means, and divide this by the standard deviation of that covariate. The ASMD is therefore always non-negative, and should not be affected by sample size. A general rule of thumb is that ASMD values over 0.1 are cause for concern, though again this can be vulnerable to small sample sizes. The function smdi_asmd from smdi creates an asmd object, which has several parts to it. Note that we set includeNA=T so that we can see the effect of missingness, as well as observed values, of other variables. This won’t make a difference for sup_df, but it will in the exercise. asmd_sup = smdi_asmd(sup_df, includeNA=T) Firstly there is a summary table, which shows the median, min and max of ASMD for each partially observed covariate. asmd_sup ## # A tibble: 1 × 4 ## covariate asmd_median asmd_min asmd_max ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 bmi 0.471 0.343 0.604 There is also a Table 1, so called because a summary table of this nature should always be included when summarising a dataset in terms of the difference between two groups. This is formatted a little strangely, as it is designed for use in printed works. This table includes the result of a statistical test (by default a chi-squared test) showing whether the differences are statistically significant. kable(asmd_sup$bmi$asmd_table1) 0 1 p test SMD n 100 3 group = 2 (%) 50 (50.0) 1 (33.3) 1.000 0.343 gender = 1 (%) 44 (44.0) 2 (66.7) 0.850 0.468 age (mean (SD)) 48.10 (13.30) 41.00 (16.46) 0.367 0.474 onset_sensory (mean (SD)) 13.00 (11.44) 24.00 (23.07) 0.114 0.604 Finally there is a plot showing each ASMD asmd_sup$bmi$asmd_plot We see that although the ASMD values are quite large (much bigger than the advised 0.1), because there are a very small number of them they are not statistically significant. Exercise A.7 Investigate the ASMD for our datasets smdi_data and opt_tmp. Of the partially observed covariates, which seem to be most strongly related to other covariates? Do any seem to be MCAR? Make sure you remove any participant ID variables, since we don’t want to include those in our analysis! Again, it might be a good idea to pair up! Click for solution Solution. We will do this just for the opt_tmp data in the solutions. asmd_opt = smdi_asmd(opt_tmp[ ,-1], includeNA=T) asmd_opt ## # A tibble: 5 × 4 ## covariate asmd_median asmd_min asmd_max ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 BMI 0.195 0.041 1.717 ## 2 Use.Tob 0.093 0.004 39.900 ## 3 Use.Alc 0.099 0.004 8.204 ## 4 Drug.Add 0.073 0.004 7.229 ## 5 Birthweight 0.340 0.004 2.556 These values are all well above 0.1, so it seems unlikely that the data are MCAR. We can look in a little more detail, first at BMI: asmd_opt$BMI$asmd_plot kable(asmd_opt$BMI$asmd_table1) 0 1 p test SMD n 750 73 Clinic (%) &lt;0.001 1.717 KY 205 (27.3) 6 ( 8.2) MN 237 (31.6) 10 (13.7) MS 192 (25.6) 0 ( 0.0) NY 116 (15.5) 57 (78.1) Group = T (%) 375 (50.0) 38 (52.1) 0.832 0.041 Age (mean (SD)) 25.91 (5.54) 26.68 (5.87) 0.256 0.136 Education (%) 0.137 0.229 8-12 yrs 441 (58.8) 38 (52.1) LT 8 yrs 134 (17.9) 20 (27.4) MT 12 yrs 175 (23.3) 15 (20.5) Public.Asstce = Yes (%) 563 (75.1) 38 (52.1) &lt;0.001 0.492 Hypertension = Y (%) 25 ( 3.3) 0 ( 0.0) 0.220 0.263 Diabetes = Yes (%) 24 ( 3.2) 0 ( 0.0) 0.235 0.257 Use.Tob (%) 0.153 0.269 No 636 (84.8) 68 (93.2) Yes 89 (11.9) 4 ( 5.5) NA 25 ( 3.3) 1 ( 1.4) Use.Alc (%) 0.583 0.146 No 709 (94.5) 71 (97.3) Yes 15 ( 2.0) 1 ( 1.4) NA 26 ( 3.5) 1 ( 1.4) Drug.Add (%) 0.434 0.161 No 720 (96.0) 71 (97.3) Yes 4 ( 0.5) 1 ( 1.4) NA 26 ( 3.5) 1 ( 1.4) Prev.preg = Yes (%) 555 (74.0) 56 (76.7) 0.715 0.063 Birthweight (mean (SD)) 3194.08 (684.92) 3247.29 (669.27) 0.529 0.079 We see that there appears to be a strong relationship between clinic and missingness of BMI. In particular, a disproportionately high number of missing BMI values seem to be from the New York (NY) clinic. There also appears to be less missingness for those with public.asstce=1 (those for whom the government paid for the delivery). Next we look at Use.Alc kable(asmd_opt$Use.Alc$asmd_table1) 0 1 p test SMD n 796 27 Clinic (%) &lt;0.001 0.874 KY 207 (26.0) 4 (14.8) MN 239 (30.0) 8 (29.6) MS 191 (24.0) 1 ( 3.7) NY 159 (20.0) 14 (51.9) Group = T (%) 399 (50.1) 14 (51.9) 1.000 0.035 Age (mean (SD)) 25.96 (5.59) 26.37 (4.99) 0.710 0.077 Education (%) 0.936 0.070 8-12 yrs 464 (58.3) 15 (55.6) LT 8 yrs 149 (18.7) 5 (18.5) MT 12 yrs 183 (23.0) 7 (25.9) Public.Asstce = Yes (%) 582 (73.1) 19 (70.4) 0.924 0.061 Hypertension = Y (%) 23 ( 2.9) 2 ( 7.4) 0.438 0.206 Diabetes = Yes (%) 24 ( 3.0) 0 ( 0.0) 0.738 0.249 BMI (mean (SD)) 27.70 (7.16) 26.88 (6.18) 0.568 0.122 Use.Tob (%) &lt;0.001 8.204 No 704 (88.4) 0 ( 0.0) Yes 92 (11.6) 1 ( 3.7) NA 0 ( 0.0) 26 (96.3) Drug.Add (%) &lt;0.001 7.079 No 790 (99.2) 1 ( 3.7) Yes 5 ( 0.6) 0 ( 0.0) NA 1 ( 0.1) 26 (96.3) Prev.preg = Yes (%) 591 (74.2) 20 (74.1) 1.000 0.004 Birthweight (mean (SD)) 3198.27 (677.67) 3225.88 (949.61) 0.873 0.033 asmd_opt$Use.Alc$asmd_plot This time the two most strongly related covariates are Use.Tob and Drug.Add. This is perhaps not surprising because they are quite similar variables. Notice that clinic still has a strong effect (the \\(x\\)-axis goes a lot higher on this plot than the one for BMI). From the table, we see that again a disproportionately high number of missing values come from the NY clinic, and that missingness in Use.Alc is much more likely if Use.Tob and/or Drug.Add are missing. A.3.2 Modelling missingness One of the most common ways to model missingness is using logistic regression. You might already have come across this in your degree, and we’ll do more about it later, but for now the box below tells you all you need to know. Logistic regression is a type of generalised linear model that is used to model a binary categorical variable \\(Y\\) (often labelled 0 and 1). In our cases the values are NA and !NA or ‘missing’ and ‘not missing’. The logistic regression model has the form \\[ \\operatorname{logit}\\left(p\\right) = \\log \\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_p x_p,\\] where \\(p = p\\left(Y=1\\right)\\) the \\(x_i\\) are explanatory variables (in our case this will be the baseline covariates and the trial arm), the \\(\\beta_i\\) are coefficients and \\(p\\) is the probability of an outcome of 1. The logit function rescales the probability (which can only be in \\(\\left[0,1\\right]\\)) to the real line, so that it works with linear combination on the right hand side. Conversely, applying the inverse logit function to the RHS gives a value in \\(\\left[0,1\\right]\\). Fitting a logistic regression model in R is very similar to fitting a linear regression. We use the function glm, which is a general function for generalised linear models. To specify that we want logistic regression, we must include the argument family = binoial(link = \"logit\"). We’ll use our nabular objects for this, since we already have variables denoting missingness. For example, we can see whether missingness of BMI in the supraclavicular dataset relates to any of the other variables. sup_nab = nabular(sup_df) sup_glm = glm(bmi_NA ~ group + gender + age + onset_sensory, data = sup_nab, family = binomial(link = &quot;logit&quot;)) summary(sup_glm) ## ## Call: ## glm(formula = bmi_NA ~ group + gender + age + onset_sensory, ## family = binomial(link = &quot;logit&quot;), data = sup_nab) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.45041 2.26927 -1.080 0.280 ## group2 -1.46042 1.38616 -1.054 0.292 ## gender1 0.99119 1.28605 0.771 0.441 ## age -0.04954 0.04609 -1.075 0.282 ## onset_sensory 0.06444 0.04116 1.566 0.117 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 27.128 on 102 degrees of freedom ## Residual deviance: 22.854 on 98 degrees of freedom ## AIC: 32.854 ## ## Number of Fisher Scoring iterations: 7 In this case none of the other variables are significant, so it would be reasonable to proceed as though the missingness of BMI is MCAR (unless there is expert knowledge to suggest that missingness might be linked to some other observed factor). This agrees with what we found in Section A.3.1 A word of caution: the default in most R functions, particularly for plotting or fitting models, is to remove all rows with any missingness. In a situation where there are missing values for multiple variables, particularly if the missingness is related, this could in itself introduce bias. Exercise A.8 Model the patterns of missingness for smdi and opt (use the opt_tmp data for this, without the severely missing variables). What do you find? To avoid typing out all the column names for the formula, you can copy and paste the output from paste(names(smdi_data), collapse = &quot; + &quot;) and delete the terms you don’t want. Click for solution Solution. Lung cancer data We can fit a few models, to see what we find. First we’ll tackle ecog_cat_NA. Missingness in ecog_cat doesn’t appear to be associated with any other baseline covariates: ecog_NA_glm1 = glm(ecog_cat_NA ~ exposure + age_num + female_cat + smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + copd_cat, data=smdi_nab, family = binomial(link=&quot;logit&quot;)) summary(ecog_NA_glm1) ## ## Call: ## glm(formula = ecog_cat_NA ~ exposure + age_num + female_cat + ## smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + ## copd_cat, family = binomial(link = &quot;logit&quot;), data = smdi_nab) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.546409 0.226805 -2.409 0.016 * ## exposure -0.089400 0.088616 -1.009 0.313 ## age_num -0.002654 0.003034 -0.875 0.382 ## female_cat1 -0.034202 0.086890 -0.394 0.694 ## smoking_cat1 0.101202 0.097823 1.035 0.301 ## physical_cat1 0.137491 0.087074 1.579 0.114 ## alk_cat1 -0.049371 0.257094 -0.192 0.848 ## histology_cat1 -0.002256 0.104115 -0.022 0.983 ## ses_cat2_middle 0.128238 0.113992 1.125 0.261 ## ses_cat3_high 0.098773 0.113447 0.871 0.384 ## copd_cat1 -0.017240 0.098015 -0.176 0.860 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 3265.9 on 2499 degrees of freedom ## Residual deviance: 3259.5 on 2489 degrees of freedom ## AIC: 3281.5 ## ## Number of Fisher Scoring iterations: 4 Now including the other variables with missing values: ecog_NA_glm2 = glm(ecog_cat_NA ~ exposure + age_num + female_cat + smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + copd_cat + egfr_cat + pdl1_num, data=smdi_nab, family = binomial(link=&quot;logit&quot;)) summary(ecog_NA_glm2) ## ## Call: ## glm(formula = ecog_cat_NA ~ exposure + age_num + female_cat + ## smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + ## copd_cat + egfr_cat + pdl1_num, family = binomial(link = &quot;logit&quot;), ## data = smdi_nab) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.063844 0.418284 -0.153 0.879 ## exposure -0.094567 0.140956 -0.671 0.502 ## age_num -0.005729 0.004484 -1.278 0.201 ## female_cat1 -0.215749 0.133629 -1.615 0.106 ## smoking_cat1 0.036868 0.139759 0.264 0.792 ## physical_cat1 0.149057 0.130846 1.139 0.255 ## alk_cat1 1.050366 0.741154 1.417 0.156 ## histology_cat1 -0.092049 0.173989 -0.529 0.597 ## ses_cat2_middle 0.215523 0.166471 1.295 0.195 ## ses_cat3_high 0.179477 0.166802 1.076 0.282 ## copd_cat1 0.106252 0.137255 0.774 0.439 ## egfr_cat1 0.082752 0.148229 0.558 0.577 ## pdl1_num -0.008005 0.006214 -1.288 0.198 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1620.9 on 1240 degrees of freedom ## Residual deviance: 1606.6 on 1228 degrees of freedom ## (1259 observations deleted due to missingness) ## AIC: 1632.6 ## ## Number of Fisher Scoring iterations: 4 None of the variables are significant, so it is probably reasonable to suppose that ecog_cat is MCAR (indeed the help file tells us it is). Now for egfr_cat: egfr_NA_glm1 = glm(egfr_cat_NA ~ exposure + age_num + female_cat + smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + copd_cat, data=smdi_nab, family = binomial(link=&quot;logit&quot;)) summary(egfr_NA_glm1) ## ## Call: ## glm(formula = egfr_cat_NA ~ exposure + age_num + female_cat + ## smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + ## copd_cat, family = binomial(link = &quot;logit&quot;), data = smdi_nab) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.776612 0.253687 -10.945 &lt; 2e-16 *** ## exposure 0.855880 0.093967 9.108 &lt; 2e-16 *** ## age_num 0.014198 0.003271 4.340 1.42e-05 *** ## female_cat1 0.781194 0.092458 8.449 &lt; 2e-16 *** ## smoking_cat1 0.626782 0.102280 6.128 8.89e-10 *** ## physical_cat1 0.513986 0.092421 5.561 2.68e-08 *** ## alk_cat1 1.116563 0.271932 4.106 4.03e-05 *** ## histology_cat1 0.807125 0.108896 7.412 1.25e-13 *** ## ses_cat2_middle -0.253823 0.119805 -2.119 0.0341 * ## ses_cat3_high -0.165891 0.118853 -1.396 0.1628 ## copd_cat1 0.579084 0.102993 5.623 1.88e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 3376.8 on 2499 degrees of freedom ## Residual deviance: 2949.9 on 2489 degrees of freedom ## AIC: 2971.9 ## ## Number of Fisher Scoring iterations: 3 egfr_NA_glm2 = glm(egfr_cat_NA ~ exposure + age_num + female_cat + smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + copd_cat + ecog_cat + pdl1_num, data=smdi_nab, family = binomial(link=&quot;logit&quot;)) summary(egfr_NA_glm2) ## ## Call: ## glm(formula = egfr_cat_NA ~ exposure + age_num + female_cat + ## smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + ## copd_cat + ecog_cat + pdl1_num, family = binomial(link = &quot;logit&quot;), ## data = smdi_nab) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -7.111213 0.592182 -12.008 &lt; 2e-16 *** ## exposure 1.003371 0.164023 6.117 9.52e-10 *** ## age_num 0.023939 0.005328 4.493 7.02e-06 *** ## female_cat1 0.886902 0.149387 5.937 2.90e-09 *** ## smoking_cat1 1.048884 0.165025 6.356 2.07e-10 *** ## physical_cat1 1.089550 0.150277 7.250 4.16e-13 *** ## alk_cat1 3.727345 0.719142 5.183 2.18e-07 *** ## histology_cat1 1.294128 0.173948 7.440 1.01e-13 *** ## ses_cat2_middle -0.072720 0.189281 -0.384 0.701 ## ses_cat3_high -0.123102 0.189587 -0.649 0.516 ## copd_cat1 0.994580 0.164698 6.039 1.55e-09 *** ## ecog_cat1 0.939474 0.152432 6.163 7.13e-10 *** ## pdl1_num 0.040946 0.007493 5.465 4.63e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1686.9 on 1273 degrees of freedom ## Residual deviance: 1209.5 on 1261 degrees of freedom ## (1226 observations deleted due to missingness) ## AIC: 1235.5 ## ## Number of Fisher Scoring iterations: 5 This time there is a definite relationship between missingness and the values of the other covariates, suggesting an MAR or MNAR mechanism. Finally, let’s model missingness in pdl1_num: pdl1_NA_glm1 = glm( pdl1_num_NA ~ exposure + age_num + female_cat + smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + copd_cat, data=smdi_nab, family = binomial(link=&quot;logit&quot;)) summary(pdl1_NA_glm1) ## ## Call: ## glm(formula = pdl1_num_NA ~ exposure + age_num + female_cat + ## smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + ## copd_cat, family = binomial(link = &quot;logit&quot;), data = smdi_nab) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.337969 0.271141 -4.935 8.03e-07 *** ## exposure -0.707361 0.112571 -6.284 3.31e-10 *** ## age_num 0.002670 0.003621 0.737 0.460901 ## female_cat1 0.115354 0.102830 1.122 0.261947 ## smoking_cat1 0.070899 0.117623 0.603 0.546663 ## physical_cat1 -0.057181 0.105602 -0.541 0.588177 ## alk_cat1 0.880597 0.260178 3.385 0.000713 *** ## histology_cat1 -0.106808 0.127451 -0.838 0.402014 ## ses_cat2_middle -0.072022 0.135175 -0.533 0.594168 ## ses_cat3_high -0.034611 0.133995 -0.258 0.796175 ## copd_cat1 0.094061 0.118031 0.797 0.425500 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2548.4 on 2499 degrees of freedom ## Residual deviance: 2488.3 on 2489 degrees of freedom ## AIC: 2510.3 ## ## Number of Fisher Scoring iterations: 4 pdl1_NA_glm2 = glm(pdl1_num_NA ~ exposure + age_num + female_cat + smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + copd_cat + ecog_cat + egfr_cat, data=smdi_nab, family = binomial(link=&quot;logit&quot;)) summary(pdl1_NA_glm2) ## ## Call: ## glm(formula = pdl1_num_NA ~ exposure + age_num + female_cat + ## smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + ## copd_cat + ecog_cat + egfr_cat, family = binomial(link = &quot;logit&quot;), ## data = smdi_nab) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.834316 0.566570 -6.768 1.31e-11 *** ## exposure -0.431716 0.221450 -1.950 0.0512 . ## age_num 0.015682 0.007177 2.185 0.0289 * ## female_cat1 0.358442 0.197460 1.815 0.0695 . ## smoking_cat1 0.300876 0.220606 1.364 0.1726 ## physical_cat1 0.500724 0.201918 2.480 0.0131 * ## alk_cat1 3.890278 0.673079 5.780 7.48e-09 *** ## histology_cat1 0.479733 0.245695 1.953 0.0509 . ## ses_cat2_middle -0.102158 0.261232 -0.391 0.6958 ## ses_cat3_high 0.125765 0.253598 0.496 0.6199 ## copd_cat1 0.882138 0.225914 3.905 9.43e-05 *** ## ecog_cat1 0.307018 0.195834 1.568 0.1169 ## egfr_cat1 0.301910 0.227109 1.329 0.1837 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 830.66 on 945 degrees of freedom ## Residual deviance: 737.55 on 933 degrees of freedom ## (1554 observations deleted due to missingness) ## AIC: 763.55 ## ## Number of Fisher Scoring iterations: 5 This time there are far fewer significantly related variables, but we can again be confident that the mechanism isn’t MCAR. Frustratingly, the only way we could determine whether the mechanisms for egfr_cat and pdl1_num was MAR or MNAR would be to measure (or otherwise procure) some of the missing data. We simply do not have the necessary information to work out which is the case. If this were a real trial, we would now talk at length with the experts/clinicians, who will have a much better understanding of the probable causes of missingness. opt Now we’ll do the same with opt_tmp. We have missingness in several variables: BMI, Use.Tob, Use.Alc, Drug.Add, Birthweight. A model fit to the data in R will remove cases with any of these missing (which for this dataset might mean a lot are removed!). So, as well as building models with all variables, we can build models using only the fully observed data, and use the _NA variables from nabular as covariates: glm_opt_BMI_allvar = glm( BMI_NA ~ Clinic + Group + Age + Education + Public.Asstce + Hypertension + Diabetes + Use.Tob + Use.Alc + Drug.Add + Prev.preg, data = nabular(opt_tmp), family = binomial(link = &quot;logit&quot;)) summary(glm_opt_BMI_allvar) ## ## Call: ## glm(formula = BMI_NA ~ Clinic + Group + Age + Education + Public.Asstce + ## Hypertension + Diabetes + Use.Tob + Use.Alc + Drug.Add + ## Prev.preg, family = binomial(link = &quot;logit&quot;), data = nabular(opt_tmp)) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.69872 0.86773 -4.263 2.02e-05 *** ## ClinicMN 0.38878 0.58170 0.668 0.5039 ## ClinicMS -15.63977 755.63175 -0.021 0.9835 ## ClinicNY 3.02941 0.51105 5.928 3.07e-09 *** ## GroupT 0.15793 0.28816 0.548 0.5837 ## Age -0.00288 0.02650 -0.109 0.9135 ## EducationLT 8 yrs 0.67635 0.35763 1.891 0.0586 . ## EducationMT 12 yrs 0.23558 0.37844 0.622 0.5336 ## Public.AsstceYes -0.18766 0.30399 -0.617 0.5370 ## HypertensionY -15.53379 1839.84596 -0.008 0.9933 ## DiabetesYes -15.18021 1942.81416 -0.008 0.9938 ## Use.TobYes -0.24898 0.59964 -0.415 0.6780 ## Use.AlcYes 0.60910 1.49054 0.409 0.6828 ## Drug.AddYes 0.09438 1.58954 0.059 0.9527 ## Prev.pregYes 0.02862 0.36074 0.079 0.9368 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 483.11 on 794 degrees of freedom ## Residual deviance: 330.17 on 780 degrees of freedom ## (28 observations deleted due to missingness) ## AIC: 360.17 ## ## Number of Fisher Scoring iterations: 18 Complete cases only: glm_opt_BMI_comp = glm( BMI_NA ~ Clinic + Group + Age + Education + Public.Asstce + Hypertension + Diabetes + Prev.preg, data = nabular(opt_tmp), family = binomial(link = &quot;logit&quot;)) summary(glm_opt_BMI_comp) ## ## Call: ## glm(formula = BMI_NA ~ Clinic + Group + Age + Education + Public.Asstce + ## Hypertension + Diabetes + Prev.preg, family = binomial(link = &quot;logit&quot;), ## data = nabular(opt_tmp)) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.522e+00 8.233e-01 -4.279 1.88e-05 *** ## ClinicMN 1.960e-01 5.469e-01 0.358 0.7200 ## ClinicMS -1.582e+01 7.539e+02 -0.021 0.9833 ## ClinicNY 2.752e+00 4.724e-01 5.825 5.72e-09 *** ## GroupT 1.292e-01 2.777e-01 0.465 0.6416 ## Age -4.618e-03 2.615e-02 -0.177 0.8599 ## EducationLT 8 yrs 6.861e-01 3.442e-01 1.993 0.0463 * ## EducationMT 12 yrs 2.811e-01 3.674e-01 0.765 0.4442 ## Public.AsstceYes -2.250e-01 2.980e-01 -0.755 0.4502 ## HypertensionY -1.633e+01 1.764e+03 -0.009 0.9926 ## DiabetesYes -1.522e+01 1.938e+03 -0.008 0.9937 ## Prev.pregYes 9.714e-02 3.527e-01 0.275 0.7830 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 493.01 on 822 degrees of freedom ## Residual deviance: 348.69 on 811 degrees of freedom ## AIC: 372.69 ## ## Number of Fisher Scoring iterations: 18 Using missingness of incomplete variables in model: glm_opt_BMI_NA = glm( BMI_NA ~ Clinic + Group + Age + Education + Public.Asstce + Hypertension + Diabetes + Use.Tob_NA + Use.Alc_NA + Drug.Add_NA + Prev.preg, data = nabular(opt_tmp), family = binomial(link = &quot;logit&quot;)) summary(glm_opt_BMI_NA) ## ## Call: ## glm(formula = BMI_NA ~ Clinic + Group + Age + Education + Public.Asstce + ## Hypertension + Diabetes + Use.Tob_NA + Use.Alc_NA + Drug.Add_NA + ## Prev.preg, family = binomial(link = &quot;logit&quot;), data = nabular(opt_tmp)) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.493e+00 8.286e-01 -4.215 2.49e-05 *** ## ClinicMN 2.307e-01 5.472e-01 0.422 0.6733 ## ClinicMS -1.582e+01 7.547e+02 -0.021 0.9833 ## ClinicNY 2.825e+00 4.740e-01 5.960 2.52e-09 *** ## GroupT 1.310e-01 2.800e-01 0.468 0.6398 ## Age -4.480e-03 2.613e-02 -0.171 0.8639 ## EducationLT 8 yrs 6.498e-01 3.462e-01 1.877 0.0605 . ## EducationMT 12 yrs 2.335e-01 3.705e-01 0.630 0.5286 ## Public.AsstceYes -2.047e-01 3.006e-01 -0.681 0.4959 ## HypertensionY -1.563e+01 1.824e+03 -0.009 0.9932 ## DiabetesYes -1.527e+01 1.945e+03 -0.008 0.9937 ## Use.Tob_NANA 1.737e+01 1.532e+04 0.001 0.9991 ## Use.Alc_NANA -3.129e+00 1.091e+04 0.000 0.9998 ## Drug.Add_NANA -1.604e+01 1.075e+04 -0.001 0.9988 ## Prev.pregYes 7.120e-02 3.553e-01 0.200 0.8412 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 493.01 on 822 degrees of freedom ## Residual deviance: 343.93 on 808 degrees of freedom ## AIC: 373.93 ## ## Number of Fisher Scoring iterations: 18 From these three models it appears that BMI is much more likely to be missing for those from the NY clinic (we already knew this from our previous investigations!): ggplot(data=nabular(opt_tmp), aes(x=Clinic, fill = BMI_NA)) + geom_bar() Perhaps the most concerning missing data in the opt dataset is in the outcome Birthweight. glm_opt_BW_allvar = glm( Birthweight_NA ~ Clinic + Group + Age + Education + Public.Asstce + Hypertension + Diabetes + BMI + Use.Tob + Use.Alc + Drug.Add + Prev.preg, data = nabular(opt_tmp), family = binomial(link = &quot;logit&quot;)) summary(glm_opt_BW_allvar) ## ## Call: ## glm(formula = Birthweight_NA ~ Clinic + Group + Age + Education + ## Public.Asstce + Hypertension + Diabetes + BMI + Use.Tob + ## Use.Alc + Drug.Add + Prev.preg, family = binomial(link = &quot;logit&quot;), ## data = nabular(opt_tmp)) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 33.729 16752.867 0.002 0.998 ## ClinicMN -133.713 20792.481 -0.006 0.995 ## ClinicMS -103.928 39728.644 -0.003 0.998 ## ClinicNY 137.894 40148.666 0.003 0.997 ## GroupT -85.621 6320.331 -0.014 0.989 ## Age -14.213 877.730 -0.016 0.987 ## EducationLT 8 yrs 38.459 39853.578 0.001 0.999 ## EducationMT 12 yrs 234.150 38187.193 0.006 0.995 ## Public.AsstceYes -196.390 12389.447 -0.016 0.987 ## HypertensionY 37.256 48814.207 0.001 0.999 ## DiabetesYes 424.730 25942.553 0.016 0.987 ## BMI 2.829 615.616 0.005 0.996 ## Use.TobYes -41.710 44071.964 -0.001 0.999 ## Use.AlcYes 26.362 75102.687 0.000 1.000 ## Drug.AddYes 369.274 101563.415 0.004 0.997 ## Prev.pregYes -152.840 9926.365 -0.015 0.988 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 3.8896e+01 on 722 degrees of freedom ## Residual deviance: 9.5715e-07 on 707 degrees of freedom ## (100 observations deleted due to missingness) ## AIC: 32 ## ## Number of Fisher Scoring iterations: 25 glm_opt_BW_comp = glm( Birthweight_NA ~ Clinic + Group + Age + Education + Public.Asstce + Hypertension + Diabetes + Prev.preg, data = nabular(opt_tmp), family = binomial(link = &quot;logit&quot;)) summary(glm_opt_BW_comp) ## ## Call: ## glm(formula = Birthweight_NA ~ Clinic + Group + Age + Education + ## Public.Asstce + Hypertension + Diabetes + Prev.preg, family = binomial(link = &quot;logit&quot;), ## data = nabular(opt_tmp)) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.39389 1.55326 -1.541 0.1233 ## ClinicMN -17.39271 1787.56149 -0.010 0.9922 ## ClinicMS -1.66204 1.20073 -1.384 0.1663 ## ClinicNY 1.24364 0.72519 1.715 0.0864 . ## GroupT -0.11738 0.56324 -0.208 0.8349 ## Age -0.04719 0.05873 -0.804 0.4217 ## EducationLT 8 yrs -0.87213 1.07459 -0.812 0.4170 ## EducationMT 12 yrs 0.35302 0.66105 0.534 0.5933 ## Public.AsstceYes -0.18665 0.66256 -0.282 0.7782 ## HypertensionY -16.92650 5484.29344 -0.003 0.9975 ## DiabetesYes 2.48332 1.25710 1.975 0.0482 * ## Prev.pregYes -0.49570 0.62136 -0.798 0.4250 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 141.83 on 822 degrees of freedom ## Residual deviance: 116.01 on 811 degrees of freedom ## AIC: 140.01 ## ## Number of Fisher Scoring iterations: 20 glm_opt_BW_NA = glm( Birthweight_NA ~ Clinic + Group + Age + Education + Public.Asstce + Hypertension + Diabetes + BMI_NA + Use.Tob_NA + Use.Alc_NA + Drug.Add_NA + Prev.preg, data = nabular(opt_tmp), family = binomial(link = &quot;logit&quot;)) summary(glm_opt_BW_NA) ## ## Call: ## glm(formula = Birthweight_NA ~ Clinic + Group + Age + Education + ## Public.Asstce + Hypertension + Diabetes + BMI_NA + Use.Tob_NA + ## Use.Alc_NA + Drug.Add_NA + Prev.preg, family = binomial(link = &quot;logit&quot;), ## data = nabular(opt_tmp)) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.018e+00 2.652e+00 -0.761 0.4465 ## ClinicMN -2.355e+01 2.073e+03 -0.011 0.9909 ## ClinicMS -3.526e+00 2.002e+00 -1.761 0.0782 . ## ClinicNY -2.028e-01 1.090e+00 -0.186 0.8524 ## GroupT 3.653e-01 9.552e-01 0.382 0.7021 ## Age -2.149e-01 1.176e-01 -1.827 0.0677 . ## EducationLT 8 yrs 1.192e+00 1.840e+00 0.648 0.5170 ## EducationMT 12 yrs 4.508e+00 2.026e+00 2.225 0.0261 * ## Public.AsstceYes -1.239e+00 1.108e+00 -1.118 0.2638 ## HypertensionY -2.131e+01 7.405e+03 -0.003 0.9977 ## DiabetesYes 4.688e+00 1.901e+00 2.466 0.0137 * ## BMI_NANA -2.385e-01 1.384e+00 -0.172 0.8632 ## Use.Tob_NANA -1.047e+01 6.859e+04 0.000 0.9999 ## Use.Alc_NANA 8.377e+00 4.876e+04 0.000 0.9999 ## Drug.Add_NANA 1.078e+01 4.824e+04 0.000 0.9998 ## Prev.pregYes -9.335e-02 9.792e-01 -0.095 0.9240 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 141.830 on 822 degrees of freedom ## Residual deviance: 42.686 on 807 degrees of freedom ## AIC: 74.686 ## ## Number of Fisher Scoring iterations: 21 It appears from this that missing valuse of Birthweight aren’t associated with missingness in the other variables. Birthweight is more likely to be missing for patients with diabetes. ggplot(data = nabular(opt_tmp), aes(x=Diabetes, fill = Birthweight_NA)) + geom_bar() A.4 What to do about missing data?! Having established that missing data can be a problem, we now need to do something about it. Methods for handling missing data fall into one of two categories: Discard some (non-missing) data Add in (‘impute’) some synthetic data We’ll look at a few versions of these methods now, and use them on our practice datasets. A.4.1 Discarding some (non-missing) data A.4.1.1 Complete case analysis The very simplest thing we can do is to discard the data for any participant who has some missing data. This is called a complete-case analysis, because we only analyse data for participants whose data are complete. There are two main problems with this: If the missing data are not MCAR, then this can induce bias. This approach can drastically reduce the amount of data Exercise A.9 For each of our datasets, how many complete cases are there? Would you recommend a complete case analysis for any of these datasets? Hint: you can use na.omit to remove all rows with at least one NA from a data frame. Click for solution Solution. All we need to do is find the number of complete rows in each dataset, and compare it to the number of participants. nrow(na.omit(sup_df)) ## [1] 100 nrow(sup_df) ## [1] 103 If we perform a complete case analysis on the sup_df data, we lose data from three participants. nrow(na.omit(smdi_data)) ## [1] 795 nrow(smdi_data) ## [1] 2500 A complete case analysis of the smdi_data would leave us with only 795 (about 32%!) of the participants. nrow(na.omit(opt_tmp)) ## [1] 720 nrow(opt_tmp) ## [1] 823 If we use a complete case analysis on opt_tmp (remember we’re ignoring some of the most missing variables for now!) we’d lose 113 cases (out of 823). There are some other methods that involve discarding some data, but for the remainder of this practical we’ll focus on methods that involve imputing synthetic data. A.4.2 Imputing data In order to keep all the data we have, even for those cases with some missing variables, we will need to impute (add in) some new data. Let’s assume we have no way of actually measuring the true value now, and our only option is to choose some value that seems appropriate. One of our main reasons for imputing data is to avoid the bias that would result from discarding incomplete cases, but we could inadvertently introduce bias if we aren’t careful (or if we are careful and unlucky) while imputing synthetic data. We’ll look at a few methods, ranging from the very simple to the moderately complex. A.4.2.1 Mean imputation In this method we simply replace each missing value by the mean of the observed values for that variable. This method is not uncommon in practice, but it can have a number of undesirable effects: If the data are not MCAR, bias is introduced The sample standard deviation is reduced Relationships between this and other variables are distorted A.4.2.2 Imputing using logic Sometimes there is missingness in a dataset that we can fill in using information about how that variable relates to other variables. For example, in the opt data, consider the two columns Use.Tob and BL.Cig.Day: Use.Tob: Self-reported participant history of tobacco use, factor; Yes, No; Blank = Missing BL.Cig.Day: Self-reported number of cigarettes per day for those with tobacco use history, numeric, range: 1-30; Blank = Missing (variable 16= Yes or blank) or non-smoker (variable 16 = No)` The first, Use.Tob, is a binary variable indicating whether or not the participant uses tobacco. The second, BL.Cig.Day is a numerical variable indicating how many cigarettes per day the participant smokes. As the data are now, there are a lot of missing values for BL.Cig.Day. However, if for a particular participant we have Use.Tob = No then we know that BL.Cig.Day is zero, and we can impute that value. Exercise A.10 Using the information in the help file, impute values for the columns BL.Cig.Day, BL.Drks.Day and N.prev.preg in the opt_df data. Make a new version of opt_df so that we can compare before and after. Note the annoying space in some of the responses - often we have \"No \"! Click for solution Solution. One important thing to remember is that if the associated categorical variable is missing, then the value for the variable we’re imputing will also be missing. We therefore need to condition on the ‘parent’ variable, rather than replace all missing values of the ‘child’ variable. For example: opt_df_imp = opt_df opt_df_imp$BL.Cig.Day[opt_df_imp$Use.Tob==&quot;No &quot;] = 0 By doing this we have ‘fixed’ 704 missing values. Similarly we cand fix those for BL.Drks.Day and N.prev.preg: opt_df_imp$BL.Drks.Day[opt_df_imp$Use.Alc==&quot;No &quot;] = 0 opt_df_imp$N.prev.preg[opt_df_imp$Prev.preg==&quot;No &quot;] = 0 We can see that this has very much improved our situation! We could do something similar for BL.Diab.Type too since this is linked to Diabetes. vis_dat(opt_df, sort_type = F) vis_dat(opt_df_imp, sort_type = F) A.4.2.3 Imputation using a regression model In this section we’re going to use the STAN regression functions from the package rstanarm. The syntax is very similar to the base R regression and glm functions, but random sampling is much simpler. The rstanarm functions use MCMC to generate samples from the posterior distribution of the regression model. There is a lot of output about chains (which you can ignore, in this practical). There are no p-values associated with coefficients, We’ve already looked at using logistic regression to understand patterns of missingness, and so it may not come as a surprise that we can use regression models to choose appropriate values for imputation. This won’t be the same model, since we’re now interested in the value, rather than the missingness. Which type of regression model we use depends on the type of the variable we’re imputing values for. If the variable is continuous, linear regression is likely to work well. If the variable is binary, we should try logistic regression. There are plenty of other types of model we could use (as well as a whole host of machine learning type models!) but in this practical we’ll stick to those two. Let’s suppose we want to use regression to impute values for pdl1_num pdl1_lm = stan_glm( pdl1_num ~ exposure + age_num + female_cat + smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + copd_cat + eventtime + status + ecog_cat + egfr_cat, data = smdi_data ) ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 3.4e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.34 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.053 seconds (Warm-up) ## Chain 1: 0.094 seconds (Sampling) ## Chain 1: 0.147 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 5e-06 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.055 seconds (Warm-up) ## Chain 2: 0.094 seconds (Sampling) ## Chain 2: 0.149 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 5e-06 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.054 seconds (Warm-up) ## Chain 3: 0.093 seconds (Sampling) ## Chain 3: 0.147 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 4e-06 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 0.054 seconds (Warm-up) ## Chain 4: 0.094 seconds (Sampling) ## Chain 4: 0.148 seconds (Total) ## Chain 4: summary(pdl1_lm) ## ## Model Info: ## function: stan_glm ## family: gaussian [identity] ## formula: pdl1_num ~ exposure + age_num + female_cat + smoking_cat + physical_cat + ## alk_cat + histology_cat + ses_cat + copd_cat + eventtime + ## status + ecog_cat + egfr_cat ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 795 ## predictors: 15 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) 36.9 2.8 33.4 36.9 40.4 ## exposure 8.8 0.7 7.9 8.8 9.8 ## age_num 0.1 0.0 0.0 0.1 0.1 ## female_cat1 -0.9 0.7 -1.8 -0.9 0.0 ## smoking_cat1 -0.6 0.8 -1.6 -0.6 0.4 ## physical_cat1 -0.8 0.8 -1.8 -0.8 0.2 ## alk_cat1 -4.6 5.6 -11.9 -4.6 2.5 ## histology_cat1 0.4 1.0 -0.8 0.4 1.7 ## ses_cat2_middle 0.6 0.9 -0.6 0.7 1.8 ## ses_cat3_high 1.0 0.9 -0.2 1.0 2.2 ## copd_cat1 0.6 0.8 -0.4 0.6 1.6 ## eventtime 0.5 0.3 0.1 0.5 0.9 ## status1 -1.7 1.4 -3.5 -1.7 0.1 ## ecog_cat1 0.4 0.7 -0.5 0.4 1.3 ## egfr_cat1 -1.5 0.9 -2.6 -1.5 -0.4 ## sigma 9.4 0.2 9.1 9.4 9.8 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 44.4 0.5 43.8 44.4 45.0 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.0 1.0 4486 ## exposure 0.0 1.0 7531 ## age_num 0.0 1.0 6556 ## female_cat1 0.0 1.0 7492 ## smoking_cat1 0.0 1.0 5816 ## physical_cat1 0.0 1.0 6823 ## alk_cat1 0.1 1.0 8182 ## histology_cat1 0.0 1.0 6902 ## ses_cat2_middle 0.0 1.0 4800 ## ses_cat3_high 0.0 1.0 4674 ## copd_cat1 0.0 1.0 6777 ## eventtime 0.0 1.0 4027 ## status1 0.0 1.0 4329 ## ecog_cat1 0.0 1.0 8694 ## egfr_cat1 0.0 1.0 7737 ## sigma 0.0 1.0 7229 ## mean_PPD 0.0 1.0 5131 ## log-posterior 0.1 1.0 1592 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). Exercise A.11 This approach is going to fail! Can you tell why? Can you suggest what to do about it? Click for solution Solution. The model involves variables that also have missingness (ecog_cat1 and egfr_cat), and so for any case with either of those missing, we won’t be able to impute a value. There are a couple of possibilities: Use the missingness of those values as an input (by creating a nabular object) Remove those variables from the model Work iteratively, generating temporary imputed values and cycling round the variables with missingness Because all our investigations suggest that ecog_cat1 is more-or-less unrelated to anything, we will remove it from the model. However, because egfr_cat is quite close to being significant in the model, we will keep it in but use missingness in the model. smdi_nab = nabular(smdi_data) pdl1_lm2 = stan_glm( pdl1_num ~ exposure + age_num + female_cat + smoking_cat + physical_cat + alk_cat + histology_cat + ses_cat + copd_cat + eventtime + status + egfr_cat_NA, data = smdi_nab ) ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 1.2e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.048 seconds (Warm-up) ## Chain 1: 0.158 seconds (Sampling) ## Chain 1: 0.206 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 6e-06 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.078 seconds (Warm-up) ## Chain 2: 0.155 seconds (Sampling) ## Chain 2: 0.233 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 5e-06 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.05 seconds (Warm-up) ## Chain 3: 0.157 seconds (Sampling) ## Chain 3: 0.207 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 4e-06 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4: Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4: Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4: Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4: Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4: Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4: Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4: Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4: Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4: Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4: Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4: Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 0.064 seconds (Warm-up) ## Chain 4: 0.156 seconds (Sampling) ## Chain 4: 0.22 seconds (Total) ## Chain 4: summary(pdl1_lm2) ## ## Model Info: ## function: stan_glm ## family: gaussian [identity] ## formula: pdl1_num ~ exposure + age_num + female_cat + smoking_cat + physical_cat + ## alk_cat + histology_cat + ses_cat + copd_cat + eventtime + ## status + egfr_cat_NA ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 1983 ## predictors: 14 ## ## Estimates: ## mean sd 10% 50% 90% ## (Intercept) 39.7 1.7 37.5 39.7 41.9 ## exposure 8.0 0.5 7.4 8.0 8.6 ## age_num 0.0 0.0 0.0 0.0 0.1 ## female_cat1 -0.4 0.5 -1.0 -0.4 0.2 ## smoking_cat1 -0.5 0.5 -1.2 -0.5 0.2 ## physical_cat1 -1.6 0.5 -2.2 -1.6 -0.9 ## alk_cat1 -1.8 1.5 -3.7 -1.8 0.1 ## histology_cat1 -0.4 0.6 -1.1 -0.4 0.4 ## ses_cat2_middle 0.1 0.6 -0.7 0.1 0.8 ## ses_cat3_high 1.1 0.6 0.4 1.1 1.9 ## copd_cat1 -0.9 0.5 -1.6 -0.9 -0.2 ## eventtime 0.6 0.2 0.3 0.6 0.8 ## status1 -1.6 0.9 -2.7 -1.6 -0.5 ## egfr_cat_NANA 4.1 0.5 3.4 4.1 4.8 ## sigma 9.8 0.2 9.6 9.8 10.0 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 46.0 0.3 45.6 46.0 46.5 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 0.0 1.0 4200 ## exposure 0.0 1.0 6085 ## age_num 0.0 1.0 5781 ## female_cat1 0.0 1.0 7769 ## smoking_cat1 0.0 1.0 5369 ## physical_cat1 0.0 1.0 6911 ## alk_cat1 0.0 1.0 7491 ## histology_cat1 0.0 1.0 8059 ## ses_cat2_middle 0.0 1.0 4911 ## ses_cat3_high 0.0 1.0 5211 ## copd_cat1 0.0 1.0 5638 ## eventtime 0.0 1.0 4341 ## status1 0.0 1.0 4383 ## egfr_cat_NANA 0.0 1.0 5841 ## sigma 0.0 1.0 6314 ## mean_PPD 0.0 1.0 5441 ## log-posterior 0.1 1.0 1625 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). We can see from the means and standard deviations that most of the coefficients are not even close to ‘significant’, but if we want to investigate some more closely we can visualise them using the plot function (separately in this case because they are quite far apart numerically) plot(pdl1_lm2, plotfun=&quot;areas&quot;, prob = 0.95, pars = c(&quot;exposure&quot;)) plot(pdl1_lm2, plotfun=&quot;areas&quot;, prob = 0.95, pars = c(&quot;age_num&quot;)) We see that for both variables, zero is not in the central 95% of the distribution. This isn’t directly relevant here but it’s nice to know about! We will now use this second model to impute values for pdl1_num. ## Split the data according to whether egfr_cat is missing smdi_pdl1_comp = smdi_nab[!is.na(smdi_nab$pdl1_num),] smdi_pdl1_miss = smdi_nab[is.na(smdi_nab$pdl1_num),] ## Use the GLM to fit values to egfr_cat pdl1_imp_lm = predict(pdl1_lm2, newdata = smdi_pdl1_miss) smdi_pdl1_miss$pdl1_num = pdl1_imp_lm ## Join the data back together again (in a different order, but it doesn&#39;t matter) smdi_imp = rbind(smdi_pdl1_miss, smdi_pdl1_comp) This might seem sensible, but actually it isn’t a very realistic use of a regression model. Compared to the observed values, the imputed values have a strong central tendency. This is because we have imputed the mean fitted value for each point, ignoring the measure of spread / uncertainty in the model. We can see this by comparing the observed values of pdl1_num to their fitted values (which we would have imputed had they been missing). smdi_pdl1_comp$pdl1_imp = predict(pdl1_lm2, newdata = smdi_pdl1_comp) # The next line just recreates the imputataion so that we can bind the datasets together smdi_pdl1_miss$pdl1_imp = predict(pdl1_lm2, newdata = smdi_pdl1_miss) smdi_pdl1_imp = rbind(smdi_pdl1_comp, smdi_pdl1_miss) ggplot(data = smdi_pdl1_imp, aes(x=pdl1_imp, y=pdl1_num, col = pdl1_num_NA)) + geom_point() + xlab(&quot;Regression fit&quot;) + ylab(&quot;Observed value / imputed value&quot;) + theme_bw() A more realistic approach would be to sample one value from the posterior distribution for each point (this is why we are using rstanarm!) smdi_pdl1_comp$pdl1_imp_rand = smdi_pdl1_comp$pdl1_num ## This time draw one point at random from the posterior distribution for each participant ## The output is a 1xdraws matrix, which we&#39;ll convert to a vector pdl1_rand_draw = posterior_predict(pdl1_lm2, newdata = smdi_pdl1_miss, draws=1) smdi_pdl1_miss$pdl1_imp_rand = as.numeric(pdl1_rand_draw) ## Now we can bind the two dataframes together and plot the randomly imputed / observed ## data against the deterministically fitted data smdi_pdl1_imp = rbind(smdi_pdl1_comp, smdi_pdl1_miss) ggplot(data = smdi_pdl1_imp, aes(x=pdl1_imp, y=pdl1_imp_rand, col = pdl1_num_NA)) + geom_point() + xlab(&quot;Regression fit&quot;) + ylab(&quot;Observed value / randomly imputed value&quot;) + theme_bw() This imputed data looks much more representative of the actual dataset. Exercise A.12 Use regression imputation to impute values for BMI in opt_tmp. A.4.3 Multiple imputation Having reached the point of acknowledging the randomness needed in imputation, a natural next step would be to draw multiple values from the posterior distribution, rather than just one. This leads to a method called multiple imputation, which is (arguably) the most widely used approach to imputing missing data, though sadly we don’t have time to go into it in this practical. References Gelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and Other Stories. Cambridge University Press. Hotelling, Harold et al. 1931. “The Generalization of Student’s Ratio.” Little, Roderick JA, and Donald B Rubin. 2019. Statistical Analysis with Missing Data. Vol. 793. John Wiley &amp; Sons. Rubin, Donald B. 1976. “Inference and Missing Data.” Biometrika 63 (3): 581–92. "],["references.html", "References", " References This sections lists the references used in the course - it will be updated as the notes are updated. Some of the more accessible (dare I say ‘interesting’) resources are linked from the notes. If you want to read any of these articles, the easiest way is to copy the title into Google scholar. Altman, Douglas G. 1990. Practical Statistics for Medical Research. CRC press. Altman, Douglas G, and J Martin Bland. 1999. “Treatment Allocation in Controlled Trials: Why Randomise?” Bmj 318 (7192): 1209–9. Cottingham, Marci D, and Jill A Fisher. 2022. “Gendered Logics of Biomedical Research: Women in US Phase i Clinical Trials.” Social Problems 69 (2): 492–509. Efron, Bradley. 1971. “Forcing a Sequential Experiment to Be Balanced.” Biometrika 58 (3): 403–17. Fentiman, Ian S, Robert D Rubens, and John L Hayward. 1983. “Control of Pleural Effusions in Patients with Breast Cancer a Randomized Trial.” Cancer 52 (4): 737–39. Freedman, LS, and Susan J White. 1976. “On the Use of Pocock and Simon’s Method for Balancing Treatment Numbers over Prognostic Factors in the Controlled Clinical Trial.” Biometrics, 691–94. Gelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and Other Stories. Cambridge University Press. Goldacre, B. 2012. Bad Pharma: How Medicine Is Broken, and How We Can Fix It. HarperCollins Publishers. https://books.google.co.uk/books?id=4amY1Q6Id4QC. Hayes, Richard J, and Lawrence H Moulton. 2017. Cluster Randomised Trials. CRC press. Health, National Institute of. 2023. “History of Women’s Participation in Clinical Research.” Office of Research on Women’s Health. https://orwh. od. nih. gov/toolkit …. https://orwh.od.nih.gov/toolkit/recruitment/history. Hjalmas, Hanson, and Kruse Hellstrom. 1998. “Long‐term Treatment with Desmopressin in Children with Primary Monosymptomatic Nocturnal Enuresis: An Open Multicentre Study.” British Journal of Urology. Hotelling, Harold et al. 1931. “The Generalization of Student’s Ratio.” Hulley, Stephen B, Steven R. Cummings, Warren S. Browner, Deborah G. Grady, and Thomas B. Newman. 2013. Designing Clinical Research, Fourth Edition. Lippincott Williams &amp; Wilkins. Kallis, P, JA Tooze, S Talbot, D Cowans, DH Bevan, and T Treasure. 1994. “Pre-Operative Aspirin Decreases Platelet Aggregation and Increases Post-Operative Blood Loss–a Prospective, Randomised, Placebo Controlled, Double-Blind Clinical Trial in 100 Patients with Chronic Stable Angina.” European Journal of Cardio-Thoracic Surgery: Official Journal of the European Association for Cardio-Thoracic Surgery 8 (8): 404–9. Kar, Sumit, Ajay Krishnan, Preetha K, and Atul Mohankar. 2012. “A Review of Antihistamines Used During Pregnancy.” Journal of Pharmacology and Pharmacotherapeutics 3 (2): 105–8. Little, Roderick JA, and Donald B Rubin. 2019. Statistical Analysis with Missing Data. Vol. 793. John Wiley &amp; Sons. Matthews, John NS. 2006. Introduction to Randomized Controlled Clinical Trials. CRC Press. Pocock, Stuart J, and Richard Simon. 1975. “Sequential Treatment Assignment with Balancing for Prognostic Factors in the Controlled Clinical Trial.” Biometrics, 103–15. Rubin, Donald B. 1976. “Inference and Missing Data.” Biometrika 63 (3): 581–92. Ruetzler, Kurt, Michael Fleck, Sabine Nabecker, Kristina Pinter, Gordian Landskron, Andrea Lassnigg, Jing You, and Daniel I Sessler. 2013. “A Randomized, Double-Blind Comparison of Licorice Versus Sugar-Water Gargle for Prevention of Postoperative Sore Throat and Postextubation Coughing.” Anesthesia &amp; Analgesia 117 (3): 614–21. Taves, Donald R. 1974. “Minimization: A New Method of Assigning Patients to Treatment and Control Groups.” Clinical Pharmacology &amp; Therapeutics 15 (5): 443–53. Treasure, Tom, and Kenneth D MacRae. 1998. “Minimisation: The Platinum Standard for Trials?: Randomisation Doesn’t Guarantee Similarity of Groups; Minimisation Does.” Bmj. British Medical Journal Publishing Group. Villar, Jesús, Carlos Ferrando, Domingo Martı́nez, Alfonso Ambrós, Tomás Muñoz, Juan A Soler, Gerardo Aguilar, et al. 2020. “Dexamethasone Treatment for the Acute Respiratory Distress Syndrome: A Multicentre, Randomised Controlled Trial.” The Lancet Respiratory Medicine 8 (3): 267–76. Vitale, Cristiana, Massimo Fini, Ilaria Spoletini, Mitja Lainscak, Petar Seferovic, and Giuseppe MC Rosano. 2017. “Under-Representation of Elderly and Women in Clinical Trials.” International Journal of Cardiology 232: 216–21. Wei, LJ. 1978. “An Application of an Urn Model to the Design of Sequential Controlled Clinical Trials.” Journal of the American Statistical Association 73 (363): 559–63. Zhong, Baoliang. 2009. “How to Calculate Sample Size in Randomized Controlled Trial?” Journal of Thoracic Disease 1 (1): 51. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
